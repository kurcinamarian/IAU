{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4110b7d-d5cd-4e78-b618-841eac6bf638",
   "metadata": {},
   "source": [
    "# Intelligent Data Analysis Project\n",
    "### Matej Bebej (50%), Marian Kurcina (50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ef770-04f0-4a1b-8968-a093a397df5b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Assignment\n",
    "- Phase 2 - Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e85d8a5-61a7-4bb5-ae86-c78db03585c6",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51d95b-e2d3-416b-bd59-4fb793c70703",
   "metadata": {},
   "source": [
    "Oxygen saturation is a key indicator of the proper functioning of the respiratory and circulatory systems. When its value drops to a critically low level, it may indicate life-threatening conditions such as hypoxemia, respiratory failure, or severe infections. In such cases, immediate intervention is essential. Traditional monitoring is performed using pulse oximeters, which, however, can be affected by noise, motion artifacts, or may have limitations in certain clinical situations.\n",
    "\n",
    "Modern machine learning–based approaches offer the possibility to estimate and predict critical oxygen saturation values with higher accuracy (critical oxygen saturation estimation). Models can utilize multimodal data, such as heart rate, respiratory rate, blood pressure, or sensor signals. By being trained on diverse datasets, it is possible to identify early warning signs of desaturation, filter out noise, and provide timely alerts even before oxygen saturation drops below a safe threshold.\n",
    "\n",
    "The goal of this assignment is to become familiar with the issue of oxygen saturation monitoring, understand the contribution of artificial intelligence, and design a solution that could improve critical care and reduce risks associated with undiagnosed hypoxemia.\n",
    "\n",
    "Each pair of students will work with an assigned dataset starting from Week 2. Your task is to predict the dependent variable “oximetry” (the predicted variable) using machine learning methods. In doing so, you will need to deal with various issues present in the data, such as inconsistent formats, missing values, outliers, and others.\n",
    "\n",
    "The expected outcomes of the project are:\n",
    "\n",
    "- the best-performing machine learning model, and\n",
    "\n",
    "- a data pipeline for building it from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce20ec-579b-4e1f-bd06-44d5324f812e",
   "metadata": {},
   "source": [
    "# Phase 2 – Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe3e813-415c-4498-8873-635a77c81807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateparser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer,PolynomialFeatures, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, RFE\n",
    "from sklearn.svm import SVR\n",
    "observation = pd.read_csv(\"dataset/observation.csv\", sep='\\t')\n",
    "patient = pd.read_csv(\"dataset/patient.csv\", sep='\\t')\n",
    "station = pd.read_csv(\"dataset/station.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c9876-3f96-4afe-bbfe-d39cb93b99a2",
   "metadata": {},
   "source": [
    "In this phase, you are expected to carry out data preprocessing for machine learning. The result should be a dataset (CSV or TSV), where each observation is described by one row.\n",
    "Since scikit-learn only works with numerical data, something must be done with the non-numerical data.\n",
    "\n",
    "Ensure the preprocessing is reproducible on both the training and test datasets, so that you can repeat the process multiple times as needed (iteratively).\n",
    "\n",
    "Because preprocessing can change the shape and characteristics of the data, you may need to perform EDA (Exploratory Data Analysis) again as necessary. These techniques will not be graded again, but document any changes in the chosen methods.\n",
    "You can solve data-related issues iteratively across all phases, as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b823b-ecb7-467d-abf2-2af9d3700a6c",
   "metadata": {},
   "source": [
    "## 2.1 Implementation of Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bb233-dc76-4391-b893-beeb833cb867",
   "metadata": {},
   "source": [
    "### A - Train–Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db092e00-b43f-4e5d-b52a-c3d53baa35ab",
   "metadata": {},
   "source": [
    "Split the data into training and test sets according to your predefined ratio. Continue working only with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbb841f-4181-4f0f-b03a-64305bcc5b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicates: 1\n"
     ]
    }
   ],
   "source": [
    "before = len(observation)\n",
    "observation = observation.drop_duplicates()\n",
    "after = len(observation)\n",
    "print(\"Removed duplicates:\", before - after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc43d6c4-18be-4e11-bb8e-cae030f9a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9684, 22)\n",
      "train shape: (9684,)\n",
      "test shape: (2422, 22)\n",
      "test shape: (2422,)\n"
     ]
    }
   ],
   "source": [
    "X = observation.drop(columns=[\"oximetry\"])\n",
    "y = observation[\"oximetry\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"train shape:\", X_train.shape)\n",
    "print(\"train shape:\", y_train.shape)\n",
    "print(\"test shape:\", X_test.shape)\n",
    "print(\"test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef1b03-c01e-4000-91bf-32d9fab0d755",
   "metadata": {},
   "source": [
    "We split data into train and test parts, with 20% of observation data being test data () and 80% being train data ()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763ed48-63b9-476b-b59c-2b2432f8dd37",
   "metadata": {},
   "source": [
    "First we preprocess train data by: \n",
    "- enforcing schemas on each data frame\n",
    "- removing latitude and longitude columns from observation since they are not medical data and have no corelation to oxymetry (as we learned in First Phase of the project - EDA)\n",
    "- removing logical outliers - values which are outside of acceptable range\n",
    "- removing records which have oxymetry missing \n",
    "- removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ae9c2-d526-4776-a642-4e80fc7a85a7",
   "metadata": {},
   "source": [
    "We create a schema - expected format for each dataset and then we check if this format is present in the dataset, if some element is not same as refered in schema we try to cast the content to the correct type, if that is not possible we insert NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041761b8-351a-4dc7-8227-333ea88209b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_schema = {\n",
    "    'location':'string',\n",
    "    'code':'string',\n",
    "    'revision':'date',\n",
    "    'station':'string',\n",
    "    'latitude':'float',\n",
    "    'longitude':'float',\n",
    "}\n",
    "observation_schema = {\n",
    "    'SpO₂':'float',\n",
    "    'HR':'float',\n",
    "    'PI':'float',\n",
    "    'RR':'float',\n",
    "    'EtCO₂':'float',\n",
    "    'FiO₂':'float',\n",
    "    'PRV':'float',\n",
    "    'BP':'float',\n",
    "    'Skin Temperature':'float',\n",
    "    'Motion/Activity index':'float',\n",
    "    'PVI':'float',\n",
    "    'Hb level':'float',\n",
    "    'SV':'float',\n",
    "    'CO':'float',\n",
    "    'Blood Flow Index':'float',\n",
    "    'PPG waveform features':'float',\n",
    "    'Signal Quality Index':'float',\n",
    "    'Respiratory effort':'float',\n",
    "    'O₂ extraction ratio':'float',\n",
    "    'SNR':'float',\n",
    "    'oximetry':'int',\n",
    "    'latitude':'float',\n",
    "    'longitude':'float'\n",
    "}\n",
    "patient_schema = {\n",
    "    'residence':'string',              \n",
    "    'current_location':'string',    \n",
    "    'blood_group':'string',          \n",
    "    'job':'string',                 \n",
    "    'mail':'string',                \n",
    "    'user_id':'int',             \n",
    "    'birthdate':'date',           \n",
    "    'company':'string',             \n",
    "    'name':'string',                \n",
    "    'username':'string',            \n",
    "    'ssn':'string',                 \n",
    "    'registration':'date',        \n",
    "    'station_ID':'int'            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a07760-5afc-43d2-9bf3-69ca14ac6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnforceSchema(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, schema=None):\n",
    "        self.schema = schema\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.schema is None:\n",
    "            return X\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        for col, col_type in self.schema.items():\n",
    "            if col not in X.columns:\n",
    "                continue\n",
    "            if col_type == 'int':\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce').astype('Int64')\n",
    "\n",
    "            elif col_type == 'float':\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)\n",
    "\n",
    "            elif col_type == 'numeric':\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "            elif col_type == 'date':\n",
    "                X[col] = X[col].apply(\n",
    "                    lambda x: dateparser.parse(str(x))\n",
    "                    if pd.notnull(x) else pd.NaT\n",
    "                )\n",
    "\n",
    "            elif col_type == 'string':\n",
    "                X[col] = X[col].astype(str)\n",
    "                X[col] = X[col].replace('nan', np.nan)\n",
    "\n",
    "            elif col_type == 'bool':\n",
    "                X[col] = (\n",
    "                    X[col]\n",
    "                    .astype(str)\n",
    "                    .str.lower()\n",
    "                    .map({'true': True, 'false': False, '1': True, '0': False})\n",
    "                )\n",
    "\n",
    "            elif col_type == 'category':\n",
    "                X[col] = X[col].astype('category')\n",
    "\n",
    "    \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed2be8-58a5-44ea-9e46-6c46143fb371",
   "metadata": {},
   "source": [
    "In observation dataset we have expected ranges for each attribute, we check if all values are within the range, if not we push the value to the edge of the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f957a35-c33d-41e2-bd14-d53f67dc7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ranges = {\n",
    "    'SpO₂': (95, 100),\n",
    "    'HR': (60, 100),\n",
    "    'PI': (0.2, 20),\n",
    "    'RR': (12, 20),\n",
    "    'EtCO₂': (35, 45),\n",
    "    'FiO₂': (21, 100),\n",
    "    'PRV': (20, 200),\n",
    "    'BP': (60, 120),\n",
    "    'Skin Temperature': (33, 38),\n",
    "    'Motion/Activity index': None,\n",
    "    'PVI': (10, 20),\n",
    "    'Hb level': (12, 18),\n",
    "    'SV': (60, 100),\n",
    "    'CO': (4, 8),\n",
    "    'Blood Flow Index': None,\n",
    "    'PPG waveform features': None,\n",
    "    'Signal Quality Index': (0, 100),\n",
    "    'Respiratory effort': None,\n",
    "    'O₂ extraction ratio': (0.2, 3),\n",
    "    'SNR': (20, 40)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09f2f6c-4e87-44e2-845b-fe707f9052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnforceValueRanges(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ranges=None):\n",
    "        self.ranges = ranges\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.ranges is None:\n",
    "            return X\n",
    "\n",
    "        for col, valid_range in self.ranges.items():\n",
    "            if col not in X.columns:\n",
    "                continue\n",
    "            if valid_range is None:\n",
    "                continue  \n",
    "\n",
    "            low, high = valid_range\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "            mask = ~X[col].between(low, high, inclusive='both')\n",
    "            X.loc[mask, col] = np.nan\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b50c6-3799-48d4-ac2a-d08c9c0d5c2d",
   "metadata": {},
   "source": [
    "For table station we have to parse the location column to get continent and city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab7e746-79f1-4f34-9d5a-a37976760c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_location(X, column='location'):\n",
    "    X = X.copy()\n",
    "    if column not in X.columns:\n",
    "        return X\n",
    "    \n",
    "    split_cols = X[column].astype(str).str.split('/', n=1, expand=True)\n",
    "    X['continent'] = split_cols[0].str.strip()\n",
    "    X['city'] = split_cols[1].str.strip() if split_cols.shape[1] > 1 else None\n",
    "    X = X.drop(columns=[column], errors='ignore')\n",
    "    return X\n",
    "\n",
    "parse_location_transformer = FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e4b1b-8bde-42eb-8f6d-005d23df1b31",
   "metadata": {},
   "source": [
    "Furthermore we create functions for other dataset transformations that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a02ac5c-7387-467a-908e-971d6b4ad0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(X, y=None, columns=None):\n",
    "    X_transformed = X.drop(columns=columns or [], errors='ignore').copy()\n",
    "    if y is not None:\n",
    "        return X_transformed, y\n",
    "    return X_transformed\n",
    "\n",
    "dropcolumns_transformer = FunctionTransformer(\n",
    "    drop_columns, kw_args={'columns': []}, validate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f44b8e5-a292-4555-9bc6-3bbc87747dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na(X, y=None, how='any', subset=None):\n",
    "    mask = X.dropna(how=how, subset=subset).index\n",
    "    X_transformed = X.loc[mask].copy()\n",
    "    if y is not None:\n",
    "        y_transformed = y.loc[mask].copy()\n",
    "        return X_transformed, y_transformed\n",
    "    return X_transformed\n",
    "\n",
    "dropna_transformer = FunctionTransformer(\n",
    "    drop_na, kw_args={'how': 'any', 'subset': None}, validate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf746e1-2fad-43be-9c86-e20295df9f0e",
   "metadata": {},
   "source": [
    "Lastly we define first version of pipelines. \n",
    "For observation pipeline we first enforce schema and ranges so all the values are of correct type and in valid range. Then we remove coordinates since these are not valid medical information and we don't to use them for our model. Then we remove null values and remove duplicates.\n",
    "For station pipeline we first enforce schema to have all columns as correct data types, then we drop station name and revision date, because we dont want to use these coulumns and they wouldn't hold any relevant information. Then we parse the location to get continent and city of the station. Lastly we drop null values and remove duplicates. This dataset is now ready to provide us additional information about the obseravtions, if it would be needed we can remove deletion of coordinates columns and add to each observation innformation about continent, country (code) and city.\n",
    "Lastly for patient dataset we only enforce schema and remove duplicates (we don't remove null values because most of the columns are partially empty), this dataset does not provide any additional information for us as we found out in 1st phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b080dbc-e1cd-43a8-8b5f-c69b335ee41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_34176\\1183780406.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[col] = X[col].replace('nan', np.nan)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>continent</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>37.35813</td>\n",
       "      <td>-6.03731</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CO</td>\n",
       "      <td>7.83389</td>\n",
       "      <td>-72.47417</td>\n",
       "      <td>America</td>\n",
       "      <td>Bogota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>26.44931</td>\n",
       "      <td>91.61356</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>37.95143</td>\n",
       "      <td>-91.77127</td>\n",
       "      <td>America</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>48.21644</td>\n",
       "      <td>9.02596</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code  latitude  longitude continent     city\n",
       "0   ES  37.35813   -6.03731    Europe   Madrid\n",
       "1   CO   7.83389  -72.47417   America   Bogota\n",
       "2   IN  26.44931   91.61356      Asia  Kolkata\n",
       "3   US  37.95143  -91.77127   America  Chicago\n",
       "4   DE  48.21644    9.02596    Europe   Berlin"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "])\n",
    "\n",
    "patient_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=patient_schema)),\n",
    "])\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train,y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "transformed_patient = patient_pipeline.fit_transform(pd.read_csv(\"dataset/patient.csv\", sep='\\t'))\n",
    "\n",
    "transformed_station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae639950-ff60-4e42-8b56-ead60d49b0d5",
   "metadata": {},
   "source": [
    "### B - Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb66f96-d6da-4c4d-8eb3-573907f45926",
   "metadata": {},
   "source": [
    "Transform the data into a format suitable for machine learning, i.e. each observation must be described by one row, and each attribute must be numeric.\n",
    "Iteratively integrate preprocessing steps from Phase 1 as part of a unified process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc8fab-112d-45d9-9277-9bad261b9746",
   "metadata": {},
   "source": [
    "For observation dataset there are no string or category features, therefore we will show encoding of categorical features on station dataset. In pipeline we will still call encoding but it will have no effect. Furtermore we will only use station and observation datasets since we have relevant information there only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a764906-9ae6-42f2-b6f4-0e90ba24edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__continent_Africa</th>\n",
       "      <th>cat__continent_America</th>\n",
       "      <th>cat__continent_Asia</th>\n",
       "      <th>cat__continent_Atlantic</th>\n",
       "      <th>cat__continent_Australia</th>\n",
       "      <th>cat__continent_Europe</th>\n",
       "      <th>cat__continent_Indian</th>\n",
       "      <th>cat__continent_Pacific</th>\n",
       "      <th>cat__city_Abidjan</th>\n",
       "      <th>cat__city_Accra</th>\n",
       "      <th>...</th>\n",
       "      <th>cat__code_UA</th>\n",
       "      <th>cat__code_US</th>\n",
       "      <th>cat__code_UY</th>\n",
       "      <th>cat__code_UZ</th>\n",
       "      <th>cat__code_VE</th>\n",
       "      <th>cat__code_VU</th>\n",
       "      <th>cat__code_YE</th>\n",
       "      <th>cat__code_ZA</th>\n",
       "      <th>remainder__latitude</th>\n",
       "      <th>remainder__longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.35813</td>\n",
       "      <td>-6.03731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.83389</td>\n",
       "      <td>-72.47417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.44931</td>\n",
       "      <td>91.61356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.95143</td>\n",
       "      <td>-91.77127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.21644</td>\n",
       "      <td>9.02596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__continent_Africa  cat__continent_America  cat__continent_Asia  \\\n",
       "0                    0.0                     0.0                  0.0   \n",
       "1                    0.0                     1.0                  0.0   \n",
       "2                    0.0                     0.0                  1.0   \n",
       "3                    0.0                     1.0                  0.0   \n",
       "4                    0.0                     0.0                  0.0   \n",
       "\n",
       "   cat__continent_Atlantic  cat__continent_Australia  cat__continent_Europe  \\\n",
       "0                      0.0                       0.0                    1.0   \n",
       "1                      0.0                       0.0                    0.0   \n",
       "2                      0.0                       0.0                    0.0   \n",
       "3                      0.0                       0.0                    0.0   \n",
       "4                      0.0                       0.0                    1.0   \n",
       "\n",
       "   cat__continent_Indian  cat__continent_Pacific  cat__city_Abidjan  \\\n",
       "0                    0.0                     0.0                0.0   \n",
       "1                    0.0                     0.0                0.0   \n",
       "2                    0.0                     0.0                0.0   \n",
       "3                    0.0                     0.0                0.0   \n",
       "4                    0.0                     0.0                0.0   \n",
       "\n",
       "   cat__city_Accra  ...  cat__code_UA  cat__code_US  cat__code_UY  \\\n",
       "0              0.0  ...           0.0           0.0           0.0   \n",
       "1              0.0  ...           0.0           0.0           0.0   \n",
       "2              0.0  ...           0.0           0.0           0.0   \n",
       "3              0.0  ...           0.0           1.0           0.0   \n",
       "4              0.0  ...           0.0           0.0           0.0   \n",
       "\n",
       "   cat__code_UZ  cat__code_VE  cat__code_VU  cat__code_YE  cat__code_ZA  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   remainder__latitude  remainder__longitude  \n",
       "0             37.35813              -6.03731  \n",
       "1              7.83389             -72.47417  \n",
       "2             26.44931              91.61356  \n",
       "3             37.95143             -91.77127  \n",
       "4             48.21644               9.02596  \n",
       "\n",
       "[5 rows x 238 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, [])\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code'])\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train,y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "transformed_station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a209fd-1e99-42a4-a77c-745d2cc75d00",
   "metadata": {},
   "source": [
    "For encoding we have put Column transformer in our pipelines, in here the transformations and scalers will be defined too. We have added remainder='passthrough' option in the column transformer to keep the columns that are not transformed in any way. After the transforms we had an issue with the step returning the numpy array which did not contain columns names, to fix this we have used .set_output(transform=\"pandas\") option for the column transformer. This will force the step to output pandas dataframe to the next step.\n",
    "For categorical columns we first replace null values with most frequent value and then we encode them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0307e7-086a-42b6-a078-9a01d1619b39",
   "metadata": {},
   "source": [
    "### C - Feature Scaling and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c29ca-ac4a-4bed-8aca-721c4916c769",
   "metadata": {},
   "source": [
    "Transform the dataset attributes for machine learning using at least the following techniques:\n",
    "\n",
    "- Scaling (2 techniques)\n",
    "- Transformers (2 techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b713aa3-5f8a-440d-b7c3-756f82ccd5bc",
   "metadata": {},
   "source": [
    " #### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c2f0b-abc0-4d8e-8496-0a62187392f6",
   "metadata": {},
   "source": [
    "##### StandardScaler\n",
    "For each numeric column, it computes formula: $z = (x - mean)/ std$, with mean = 0 and std = 1\n",
    "StandardScaler makes each column \"comparable\" in scale. Prevents some features being too influential simply because of their scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f3638d6-e18f-4a15-a737-b0be71d8688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__HR</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__FiO₂</th>\n",
       "      <th>num__PRV</th>\n",
       "      <th>num__BP</th>\n",
       "      <th>num__Skin Temperature</th>\n",
       "      <th>num__Motion/Activity index</th>\n",
       "      <th>num__PVI</th>\n",
       "      <th>num__Hb level</th>\n",
       "      <th>num__SV</th>\n",
       "      <th>num__CO</th>\n",
       "      <th>num__Blood Flow Index</th>\n",
       "      <th>num__PPG waveform features</th>\n",
       "      <th>num__Signal Quality Index</th>\n",
       "      <th>num__Respiratory effort</th>\n",
       "      <th>num__O₂ extraction ratio</th>\n",
       "      <th>num__SNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.953852</td>\n",
       "      <td>0.032699</td>\n",
       "      <td>1.222765</td>\n",
       "      <td>0.732980</td>\n",
       "      <td>0.382418</td>\n",
       "      <td>-0.229489</td>\n",
       "      <td>0.320303</td>\n",
       "      <td>1.900541</td>\n",
       "      <td>0.891793</td>\n",
       "      <td>1.388571</td>\n",
       "      <td>0.314696</td>\n",
       "      <td>-0.872217</td>\n",
       "      <td>0.530179</td>\n",
       "      <td>-0.268116</td>\n",
       "      <td>-0.754105</td>\n",
       "      <td>-0.465557</td>\n",
       "      <td>-0.706253</td>\n",
       "      <td>1.279517</td>\n",
       "      <td>-0.539533</td>\n",
       "      <td>1.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-0.991307</td>\n",
       "      <td>0.266432</td>\n",
       "      <td>0.549494</td>\n",
       "      <td>-1.610561</td>\n",
       "      <td>-0.139343</td>\n",
       "      <td>1.056711</td>\n",
       "      <td>0.443323</td>\n",
       "      <td>0.585270</td>\n",
       "      <td>-0.307794</td>\n",
       "      <td>-0.968697</td>\n",
       "      <td>-1.202764</td>\n",
       "      <td>-0.297119</td>\n",
       "      <td>0.206366</td>\n",
       "      <td>-0.165222</td>\n",
       "      <td>0.820335</td>\n",
       "      <td>0.229577</td>\n",
       "      <td>-0.751795</td>\n",
       "      <td>0.979515</td>\n",
       "      <td>0.789101</td>\n",
       "      <td>-1.425010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-2.102740</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.226362</td>\n",
       "      <td>-3.443886</td>\n",
       "      <td>-0.014848</td>\n",
       "      <td>1.979283</td>\n",
       "      <td>-0.563047</td>\n",
       "      <td>-0.775902</td>\n",
       "      <td>-0.102475</td>\n",
       "      <td>2.708076</td>\n",
       "      <td>0.082070</td>\n",
       "      <td>0.374047</td>\n",
       "      <td>-0.398170</td>\n",
       "      <td>0.088075</td>\n",
       "      <td>-0.844645</td>\n",
       "      <td>-0.020597</td>\n",
       "      <td>1.879169</td>\n",
       "      <td>1.608523</td>\n",
       "      <td>0.392014</td>\n",
       "      <td>-1.071256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.522682</td>\n",
       "      <td>-0.408683</td>\n",
       "      <td>-0.316020</td>\n",
       "      <td>-0.381465</td>\n",
       "      <td>0.273402</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>-0.691574</td>\n",
       "      <td>-0.831748</td>\n",
       "      <td>-2.301060</td>\n",
       "      <td>-1.472041</td>\n",
       "      <td>-1.174046</td>\n",
       "      <td>1.731231</td>\n",
       "      <td>0.810748</td>\n",
       "      <td>-0.429002</td>\n",
       "      <td>-1.756642</td>\n",
       "      <td>-0.921236</td>\n",
       "      <td>0.397168</td>\n",
       "      <td>-0.562005</td>\n",
       "      <td>1.130631</td>\n",
       "      <td>0.916572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.634981</td>\n",
       "      <td>0.591865</td>\n",
       "      <td>0.352991</td>\n",
       "      <td>0.862953</td>\n",
       "      <td>1.823320</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>0.331392</td>\n",
       "      <td>-1.149611</td>\n",
       "      <td>-1.598345</td>\n",
       "      <td>-0.775176</td>\n",
       "      <td>1.254505</td>\n",
       "      <td>-2.122586</td>\n",
       "      <td>1.276494</td>\n",
       "      <td>0.048805</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.402615</td>\n",
       "      <td>0.990483</td>\n",
       "      <td>0.075276</td>\n",
       "      <td>1.134043</td>\n",
       "      <td>1.293153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__HR   num__PI   num__RR  num__EtCO₂  num__FiO₂  \\\n",
       "108     1.953852  0.032699  1.222765  0.732980    0.382418  -0.229489   \n",
       "12092  -0.991307  0.266432  0.549494 -1.610561   -0.139343   1.056711   \n",
       "9658   -2.102740  0.593181  0.226362 -3.443886   -0.014848   1.979283   \n",
       "2929   -0.522682 -0.408683 -0.316020 -0.381465    0.273402   0.226677   \n",
       "10405   0.634981  0.591865  0.352991  0.862953    1.823320  -0.107193   \n",
       "\n",
       "       num__PRV   num__BP  num__Skin Temperature  num__Motion/Activity index  \\\n",
       "108    0.320303  1.900541               0.891793                    1.388571   \n",
       "12092  0.443323  0.585270              -0.307794                   -0.968697   \n",
       "9658  -0.563047 -0.775902              -0.102475                    2.708076   \n",
       "2929  -0.691574 -0.831748              -2.301060                   -1.472041   \n",
       "10405  0.331392 -1.149611              -1.598345                   -0.775176   \n",
       "\n",
       "       num__PVI  num__Hb level   num__SV   num__CO  num__Blood Flow Index  \\\n",
       "108    0.314696      -0.872217  0.530179 -0.268116              -0.754105   \n",
       "12092 -1.202764      -0.297119  0.206366 -0.165222               0.820335   \n",
       "9658   0.082070       0.374047 -0.398170  0.088075              -0.844645   \n",
       "2929  -1.174046       1.731231  0.810748 -0.429002              -1.756642   \n",
       "10405  1.254505      -2.122586  1.276494  0.048805               0.019867   \n",
       "\n",
       "       num__PPG waveform features  num__Signal Quality Index  \\\n",
       "108                     -0.465557                  -0.706253   \n",
       "12092                    0.229577                  -0.751795   \n",
       "9658                    -0.020597                   1.879169   \n",
       "2929                    -0.921236                   0.397168   \n",
       "10405                    0.402615                   0.990483   \n",
       "\n",
       "       num__Respiratory effort  num__O₂ extraction ratio  num__SNR  \n",
       "108                   1.279517                 -0.539533  1.003425  \n",
       "12092                 0.979515                  0.789101 -1.425010  \n",
       "9658                  1.608523                  0.392014 -1.071256  \n",
       "2929                 -0.562005                  1.130631  0.916572  \n",
       "10405                 0.075276                  1.134043  1.293153  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    #(\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train,y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84cbe10-2896-4806-849e-bbd5c0ad6d12",
   "metadata": {},
   "source": [
    "##### MinMax Scaler\n",
    "Maps the minimum of each feature to −1 and the maximum to 1. It uses following formula: $z = -1 + 2 * ((x - x(min) / (x(max) - x(min))$\n",
    "Preserves the original shape of the distribution, only makes the values more tightly bounded.\n",
    "Good when we need values from smaller ranges (here from -1 to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939b79b1-5e11-4a0a-9562-9249b2322b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__HR</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__FiO₂</th>\n",
       "      <th>num__PRV</th>\n",
       "      <th>num__BP</th>\n",
       "      <th>num__Skin Temperature</th>\n",
       "      <th>num__Motion/Activity index</th>\n",
       "      <th>num__PVI</th>\n",
       "      <th>num__Hb level</th>\n",
       "      <th>num__SV</th>\n",
       "      <th>num__CO</th>\n",
       "      <th>num__Blood Flow Index</th>\n",
       "      <th>num__PPG waveform features</th>\n",
       "      <th>num__Signal Quality Index</th>\n",
       "      <th>num__Respiratory effort</th>\n",
       "      <th>num__O₂ extraction ratio</th>\n",
       "      <th>num__SNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.756534</td>\n",
       "      <td>-0.086035</td>\n",
       "      <td>0.385460</td>\n",
       "      <td>0.344547</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>-0.025558</td>\n",
       "      <td>0.050369</td>\n",
       "      <td>0.542354</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.275965</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>-0.263522</td>\n",
       "      <td>0.448987</td>\n",
       "      <td>-0.978535</td>\n",
       "      <td>-0.192627</td>\n",
       "      <td>-0.083837</td>\n",
       "      <td>-0.217594</td>\n",
       "      <td>0.468981</td>\n",
       "      <td>-0.319556</td>\n",
       "      <td>0.574116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-0.248824</td>\n",
       "      <td>-0.030191</td>\n",
       "      <td>0.143535</td>\n",
       "      <td>-0.409846</td>\n",
       "      <td>-0.080694</td>\n",
       "      <td>0.306877</td>\n",
       "      <td>0.083884</td>\n",
       "      <td>0.219843</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>-0.347967</td>\n",
       "      <td>-0.328556</td>\n",
       "      <td>-0.106338</td>\n",
       "      <td>0.392417</td>\n",
       "      <td>-0.973574</td>\n",
       "      <td>0.213642</td>\n",
       "      <td>0.081514</td>\n",
       "      <td>-0.229690</td>\n",
       "      <td>0.397657</td>\n",
       "      <td>0.448137</td>\n",
       "      <td>-0.825119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-0.628222</td>\n",
       "      <td>0.047877</td>\n",
       "      <td>0.027425</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.050365</td>\n",
       "      <td>0.545327</td>\n",
       "      <td>-0.190286</td>\n",
       "      <td>-0.113924</td>\n",
       "      <td>0.060747</td>\n",
       "      <td>0.625218</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.077104</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>-0.961361</td>\n",
       "      <td>-0.215990</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.469048</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>0.218698</td>\n",
       "      <td>-0.621290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.088854</td>\n",
       "      <td>-0.191492</td>\n",
       "      <td>-0.167469</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.092344</td>\n",
       "      <td>-0.225301</td>\n",
       "      <td>-0.127617</td>\n",
       "      <td>-0.472883</td>\n",
       "      <td>-0.481194</td>\n",
       "      <td>-0.320944</td>\n",
       "      <td>0.448046</td>\n",
       "      <td>0.498002</td>\n",
       "      <td>-0.986293</td>\n",
       "      <td>-0.451321</td>\n",
       "      <td>-0.192228</td>\n",
       "      <td>0.075455</td>\n",
       "      <td>0.031171</td>\n",
       "      <td>0.645475</td>\n",
       "      <td>0.524072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.306325</td>\n",
       "      <td>0.047562</td>\n",
       "      <td>0.072926</td>\n",
       "      <td>0.386386</td>\n",
       "      <td>0.397450</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.053390</td>\n",
       "      <td>-0.205559</td>\n",
       "      <td>-0.302323</td>\n",
       "      <td>-0.296745</td>\n",
       "      <td>0.322789</td>\n",
       "      <td>-0.605270</td>\n",
       "      <td>0.579367</td>\n",
       "      <td>-0.963255</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.122674</td>\n",
       "      <td>0.233029</td>\n",
       "      <td>0.182680</td>\n",
       "      <td>0.647446</td>\n",
       "      <td>0.741054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__HR   num__PI   num__RR  num__EtCO₂  num__FiO₂  \\\n",
       "108     0.756534 -0.086035  0.385460  0.344547    0.046418  -0.025558   \n",
       "12092  -0.248824 -0.030191  0.143535 -0.409846   -0.080694   0.306877   \n",
       "9658   -0.628222  0.047877  0.027425 -1.000000   -0.050365   0.545327   \n",
       "2929   -0.088854 -0.191492 -0.167469 -0.014196    0.019859   0.092344   \n",
       "10405   0.306325  0.047562  0.072926  0.386386    0.397450   0.006051   \n",
       "\n",
       "       num__PRV   num__BP  num__Skin Temperature  num__Motion/Activity index  \\\n",
       "108    0.050369  0.542354               0.302071                    0.275965   \n",
       "12092  0.083884  0.219843               0.010913                   -0.347967   \n",
       "9658  -0.190286 -0.113924               0.060747                    0.625218   \n",
       "2929  -0.225301 -0.127617              -0.472883                   -0.481194   \n",
       "10405  0.053390 -0.205559              -0.302323                   -0.296745   \n",
       "\n",
       "       num__PVI  num__Hb level   num__SV   num__CO  num__Blood Flow Index  \\\n",
       "108    0.073675      -0.263522  0.448987 -0.978535              -0.192627   \n",
       "12092 -0.328556      -0.106338  0.392417 -0.973574               0.213642   \n",
       "9658   0.012013       0.077104  0.286804 -0.961361              -0.215990   \n",
       "2929  -0.320944       0.448046  0.498002 -0.986293              -0.451321   \n",
       "10405  0.322789      -0.605270  0.579367 -0.963255               0.007089   \n",
       "\n",
       "       num__PPG waveform features  num__Signal Quality Index  \\\n",
       "108                     -0.083837                  -0.217594   \n",
       "12092                    0.081514                  -0.229690   \n",
       "9658                     0.022005                   0.469048   \n",
       "2929                    -0.192228                   0.075455   \n",
       "10405                    0.122674                   0.233029   \n",
       "\n",
       "       num__Respiratory effort  num__O₂ extraction ratio  num__SNR  \n",
       "108                   0.468981                 -0.319556  0.574116  \n",
       "12092                 0.397657                  0.448137 -0.825119  \n",
       "9658                  0.547200                  0.218698 -0.621290  \n",
       "2929                  0.031171                  0.645475  0.524072  \n",
       "10405                 0.182680                  0.647446  0.741054  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    #(\"scaler\", StandardScaler()),\n",
    "    (\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train,y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12649e6f-4ae8-40b2-be35-997ae6a330a0",
   "metadata": {},
   "source": [
    "We have put both scalers into our pipeline, but one will be commented out. In need we can use any of the scalers easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7d0d6-fea6-43ea-826d-95083b760724",
   "metadata": {},
   "source": [
    "#### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b130ef5-e851-4698-81e8-5b0d60e8d0bd",
   "metadata": {},
   "source": [
    "##### PowerTransformer (Yeo-Johnson method)\n",
    "\n",
    "Makes given data from skewed and non-normal into more Gaussian like shape.\n",
    "There is a big chance of model behaving better when the inputs we feed him are closer to normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4c91c77-ef0e-462d-9d35-47161d9e5130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__HR</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__FiO₂</th>\n",
       "      <th>num__PRV</th>\n",
       "      <th>num__BP</th>\n",
       "      <th>num__Skin Temperature</th>\n",
       "      <th>num__Motion/Activity index</th>\n",
       "      <th>num__PVI</th>\n",
       "      <th>num__Hb level</th>\n",
       "      <th>num__SV</th>\n",
       "      <th>num__CO</th>\n",
       "      <th>num__Blood Flow Index</th>\n",
       "      <th>num__PPG waveform features</th>\n",
       "      <th>num__Signal Quality Index</th>\n",
       "      <th>num__Respiratory effort</th>\n",
       "      <th>num__O₂ extraction ratio</th>\n",
       "      <th>num__SNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2.241529</td>\n",
       "      <td>0.035210</td>\n",
       "      <td>1.186962</td>\n",
       "      <td>0.715950</td>\n",
       "      <td>0.376513</td>\n",
       "      <td>-0.229246</td>\n",
       "      <td>0.321797</td>\n",
       "      <td>1.904921</td>\n",
       "      <td>0.892083</td>\n",
       "      <td>1.385230</td>\n",
       "      <td>0.316855</td>\n",
       "      <td>-0.871952</td>\n",
       "      <td>0.524744</td>\n",
       "      <td>-0.225364</td>\n",
       "      <td>-0.755669</td>\n",
       "      <td>-0.466986</td>\n",
       "      <td>-0.704109</td>\n",
       "      <td>1.284423</td>\n",
       "      <td>-0.532905</td>\n",
       "      <td>1.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-1.009404</td>\n",
       "      <td>0.268736</td>\n",
       "      <td>0.608312</td>\n",
       "      <td>-1.543483</td>\n",
       "      <td>-0.146314</td>\n",
       "      <td>1.056657</td>\n",
       "      <td>0.444607</td>\n",
       "      <td>0.584205</td>\n",
       "      <td>-0.306466</td>\n",
       "      <td>-0.968297</td>\n",
       "      <td>-1.203758</td>\n",
       "      <td>-0.296211</td>\n",
       "      <td>0.198872</td>\n",
       "      <td>-0.039309</td>\n",
       "      <td>0.819897</td>\n",
       "      <td>0.228158</td>\n",
       "      <td>-0.749841</td>\n",
       "      <td>0.980227</td>\n",
       "      <td>0.792622</td>\n",
       "      <td>-1.450753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-1.890576</td>\n",
       "      <td>0.594747</td>\n",
       "      <td>0.309697</td>\n",
       "      <td>-2.918234</td>\n",
       "      <td>-0.021913</td>\n",
       "      <td>1.978583</td>\n",
       "      <td>-0.561582</td>\n",
       "      <td>-0.776612</td>\n",
       "      <td>-0.101027</td>\n",
       "      <td>2.687207</td>\n",
       "      <td>0.084497</td>\n",
       "      <td>0.374874</td>\n",
       "      <td>-0.405067</td>\n",
       "      <td>0.332801</td>\n",
       "      <td>-0.845873</td>\n",
       "      <td>-0.022195</td>\n",
       "      <td>1.871305</td>\n",
       "      <td>1.619050</td>\n",
       "      <td>0.399880</td>\n",
       "      <td>-1.073147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.588099</td>\n",
       "      <td>-0.406534</td>\n",
       "      <td>-0.229970</td>\n",
       "      <td>-0.431378</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>0.226903</td>\n",
       "      <td>-0.690361</td>\n",
       "      <td>-0.832310</td>\n",
       "      <td>-2.307414</td>\n",
       "      <td>-1.476076</td>\n",
       "      <td>-1.174869</td>\n",
       "      <td>1.729279</td>\n",
       "      <td>0.808427</td>\n",
       "      <td>-0.597474</td>\n",
       "      <td>-1.751408</td>\n",
       "      <td>-0.921782</td>\n",
       "      <td>0.399576</td>\n",
       "      <td>-0.567079</td>\n",
       "      <td>1.128137</td>\n",
       "      <td>0.918762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.597934</td>\n",
       "      <td>0.593434</td>\n",
       "      <td>0.428541</td>\n",
       "      <td>0.858602</td>\n",
       "      <td>1.840109</td>\n",
       "      <td>-0.106945</td>\n",
       "      <td>0.332869</td>\n",
       "      <td>-1.149125</td>\n",
       "      <td>-1.600628</td>\n",
       "      <td>-0.773598</td>\n",
       "      <td>1.253010</td>\n",
       "      <td>-2.126095</td>\n",
       "      <td>1.282045</td>\n",
       "      <td>0.332801</td>\n",
       "      <td>0.017320</td>\n",
       "      <td>0.401428</td>\n",
       "      <td>0.990062</td>\n",
       "      <td>0.069165</td>\n",
       "      <td>1.131478</td>\n",
       "      <td>1.276149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__HR   num__PI   num__RR  num__EtCO₂  num__FiO₂  \\\n",
       "108     2.241529  0.035210  1.186962  0.715950    0.376513  -0.229246   \n",
       "12092  -1.009404  0.268736  0.608312 -1.543483   -0.146314   1.056657   \n",
       "9658   -1.890576  0.594747  0.309697 -2.918234   -0.021913   1.978583   \n",
       "2929   -0.588099 -0.406534 -0.229970 -0.431378    0.266957   0.226903   \n",
       "10405   0.597934  0.593434  0.428541  0.858602    1.840109  -0.106945   \n",
       "\n",
       "       num__PRV   num__BP  num__Skin Temperature  num__Motion/Activity index  \\\n",
       "108    0.321797  1.904921               0.892083                    1.385230   \n",
       "12092  0.444607  0.584205              -0.306466                   -0.968297   \n",
       "9658  -0.561582 -0.776612              -0.101027                    2.687207   \n",
       "2929  -0.690361 -0.832310              -2.307414                   -1.476076   \n",
       "10405  0.332869 -1.149125              -1.600628                   -0.773598   \n",
       "\n",
       "       num__PVI  num__Hb level   num__SV   num__CO  num__Blood Flow Index  \\\n",
       "108    0.316855      -0.871952  0.524744 -0.225364              -0.755669   \n",
       "12092 -1.203758      -0.296211  0.198872 -0.039309               0.819897   \n",
       "9658   0.084497       0.374874 -0.405067  0.332801              -0.845873   \n",
       "2929  -1.174869       1.729279  0.808427 -0.597474              -1.751408   \n",
       "10405  1.253010      -2.126095  1.282045  0.332801               0.017320   \n",
       "\n",
       "       num__PPG waveform features  num__Signal Quality Index  \\\n",
       "108                     -0.466986                  -0.704109   \n",
       "12092                    0.228158                  -0.749841   \n",
       "9658                    -0.022195                   1.871305   \n",
       "2929                    -0.921782                   0.399576   \n",
       "10405                    0.401428                   0.990062   \n",
       "\n",
       "       num__Respiratory effort  num__O₂ extraction ratio  num__SNR  \n",
       "108                   1.284423                 -0.532905  1.001671  \n",
       "12092                 0.980227                  0.792622 -1.450753  \n",
       "9658                  1.619050                  0.399880 -1.073147  \n",
       "2929                 -0.567079                  1.128137  0.918762  \n",
       "10405                 0.069165                  1.131478  1.276149  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    #(\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    #(\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train,y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71d989-5857-463e-ba30-b83f2f13caf3",
   "metadata": {},
   "source": [
    "##### Polynomial features\n",
    "\n",
    "We create new features which are results of us multiplying existing ones and by that expands the feature space.\n",
    "We are hoping that this will result in boosting accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49dbbff-7126-4583-bfba-ac5ab9b42ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__HR</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__FiO₂</th>\n",
       "      <th>num__PRV</th>\n",
       "      <th>num__BP</th>\n",
       "      <th>num__Skin Temperature</th>\n",
       "      <th>num__Motion/Activity index</th>\n",
       "      <th>...</th>\n",
       "      <th>num__Signal Quality Index^2</th>\n",
       "      <th>num__Signal Quality Index Respiratory effort</th>\n",
       "      <th>num__Signal Quality Index O₂ extraction ratio</th>\n",
       "      <th>num__Signal Quality Index SNR</th>\n",
       "      <th>num__Respiratory effort^2</th>\n",
       "      <th>num__Respiratory effort O₂ extraction ratio</th>\n",
       "      <th>num__Respiratory effort SNR</th>\n",
       "      <th>num__O₂ extraction ratio^2</th>\n",
       "      <th>num__O₂ extraction ratio SNR</th>\n",
       "      <th>num__SNR^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.953852</td>\n",
       "      <td>0.032699</td>\n",
       "      <td>1.222765</td>\n",
       "      <td>0.732980</td>\n",
       "      <td>0.382418</td>\n",
       "      <td>-0.229489</td>\n",
       "      <td>0.320303</td>\n",
       "      <td>1.900541</td>\n",
       "      <td>0.891793</td>\n",
       "      <td>1.388571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755394</td>\n",
       "      <td>0.107460</td>\n",
       "      <td>-0.820347</td>\n",
       "      <td>-0.063873</td>\n",
       "      <td>1.335851</td>\n",
       "      <td>0.772486</td>\n",
       "      <td>1.776561</td>\n",
       "      <td>-0.579083</td>\n",
       "      <td>0.527485</td>\n",
       "      <td>1.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-0.991307</td>\n",
       "      <td>0.266432</td>\n",
       "      <td>0.549494</td>\n",
       "      <td>-1.610561</td>\n",
       "      <td>-0.139343</td>\n",
       "      <td>1.056711</td>\n",
       "      <td>0.443323</td>\n",
       "      <td>0.585270</td>\n",
       "      <td>-0.307794</td>\n",
       "      <td>-0.968697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.791837</td>\n",
       "      <td>-0.086663</td>\n",
       "      <td>-0.415261</td>\n",
       "      <td>-1.279778</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>1.311060</td>\n",
       "      <td>-0.454108</td>\n",
       "      <td>0.765317</td>\n",
       "      <td>-0.922922</td>\n",
       "      <td>-1.320641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-2.102740</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.226362</td>\n",
       "      <td>-3.443886</td>\n",
       "      <td>-0.014848</td>\n",
       "      <td>1.979283</td>\n",
       "      <td>-0.563047</td>\n",
       "      <td>-0.775902</td>\n",
       "      <td>-0.102475</td>\n",
       "      <td>2.708076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.158753</td>\n",
       "      <td>2.907412</td>\n",
       "      <td>1.933907</td>\n",
       "      <td>0.532495</td>\n",
       "      <td>1.759074</td>\n",
       "      <td>1.646046</td>\n",
       "      <td>0.192317</td>\n",
       "      <td>0.342165</td>\n",
       "      <td>-0.755059</td>\n",
       "      <td>-1.052870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.522682</td>\n",
       "      <td>-0.408683</td>\n",
       "      <td>-0.316020</td>\n",
       "      <td>-0.381465</td>\n",
       "      <td>0.273402</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>-0.691574</td>\n",
       "      <td>-0.831748</td>\n",
       "      <td>-2.301060</td>\n",
       "      <td>-1.472041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285114</td>\n",
       "      <td>-0.078018</td>\n",
       "      <td>0.871203</td>\n",
       "      <td>0.913418</td>\n",
       "      <td>-0.627741</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.145476</td>\n",
       "      <td>1.143825</td>\n",
       "      <td>1.468764</td>\n",
       "      <td>0.897621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.634981</td>\n",
       "      <td>0.591865</td>\n",
       "      <td>0.352991</td>\n",
       "      <td>0.862953</td>\n",
       "      <td>1.823320</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>0.331392</td>\n",
       "      <td>-1.149611</td>\n",
       "      <td>-1.598345</td>\n",
       "      <td>-0.775176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969698</td>\n",
       "      <td>0.817267</td>\n",
       "      <td>1.478397</td>\n",
       "      <td>1.742877</td>\n",
       "      <td>-0.026031</td>\n",
       "      <td>0.629410</td>\n",
       "      <td>0.943214</td>\n",
       "      <td>1.147674</td>\n",
       "      <td>1.835078</td>\n",
       "      <td>1.352410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__HR   num__PI   num__RR  num__EtCO₂  num__FiO₂  \\\n",
       "108     1.953852  0.032699  1.222765  0.732980    0.382418  -0.229489   \n",
       "12092  -0.991307  0.266432  0.549494 -1.610561   -0.139343   1.056711   \n",
       "9658   -2.102740  0.593181  0.226362 -3.443886   -0.014848   1.979283   \n",
       "2929   -0.522682 -0.408683 -0.316020 -0.381465    0.273402   0.226677   \n",
       "10405   0.634981  0.591865  0.352991  0.862953    1.823320  -0.107193   \n",
       "\n",
       "       num__PRV   num__BP  num__Skin Temperature  num__Motion/Activity index  \\\n",
       "108    0.320303  1.900541               0.891793                    1.388571   \n",
       "12092  0.443323  0.585270              -0.307794                   -0.968697   \n",
       "9658  -0.563047 -0.775902              -0.102475                    2.708076   \n",
       "2929  -0.691574 -0.831748              -2.301060                   -1.472041   \n",
       "10405  0.331392 -1.149611              -1.598345                   -0.775176   \n",
       "\n",
       "       ...  num__Signal Quality Index^2  \\\n",
       "108    ...                    -0.755394   \n",
       "12092  ...                    -0.791837   \n",
       "9658   ...                     2.158753   \n",
       "2929   ...                     0.285114   \n",
       "10405  ...                     0.969698   \n",
       "\n",
       "       num__Signal Quality Index Respiratory effort  \\\n",
       "108                                        0.107460   \n",
       "12092                                     -0.086663   \n",
       "9658                                       2.907412   \n",
       "2929                                      -0.078018   \n",
       "10405                                      0.817267   \n",
       "\n",
       "       num__Signal Quality Index O₂ extraction ratio  \\\n",
       "108                                        -0.820347   \n",
       "12092                                      -0.415261   \n",
       "9658                                        1.933907   \n",
       "2929                                        0.871203   \n",
       "10405                                       1.478397   \n",
       "\n",
       "       num__Signal Quality Index SNR  num__Respiratory effort^2  \\\n",
       "108                        -0.063873                   1.335851   \n",
       "12092                      -1.279778                   0.969072   \n",
       "9658                        0.532495                   1.759074   \n",
       "2929                        0.913418                  -0.627741   \n",
       "10405                       1.742877                  -0.026031   \n",
       "\n",
       "       num__Respiratory effort O₂ extraction ratio  \\\n",
       "108                                       0.772486   \n",
       "12092                                     1.311060   \n",
       "9658                                      1.646046   \n",
       "2929                                      0.004471   \n",
       "10405                                     0.629410   \n",
       "\n",
       "       num__Respiratory effort SNR  num__O₂ extraction ratio^2  \\\n",
       "108                       1.776561                   -0.579083   \n",
       "12092                    -0.454108                    0.765317   \n",
       "9658                      0.192317                    0.342165   \n",
       "2929                      0.145476                    1.143825   \n",
       "10405                     0.943214                    1.147674   \n",
       "\n",
       "       num__O₂ extraction ratio SNR  num__SNR^2  \n",
       "108                        0.527485    1.000101  \n",
       "12092                     -0.922922   -1.320641  \n",
       "9658                      -0.755059   -1.052870  \n",
       "2929                       1.468764    0.897621  \n",
       "10405                      1.835078    1.352410  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    #(\"power\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    #(\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)), \n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='passthrough').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train,y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8b512-ae65-4923-b382-c2cba6c23ceb",
   "metadata": {},
   "source": [
    "### D - Justification and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d28cc5-25af-4025-b8ee-366d9461eb9c",
   "metadata": {},
   "source": [
    "We transformed the observation dataset to make it compatible with model training by ensuring it contains only numerical values. We also demonstrated two different methods for data transformation and scaling, which help the model learn more effectively. For each method we described how the process works and what this hopes to achieve. In 3rd phase we can use these methods to make our models more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9339e-5c24-414f-858d-500c944d687d",
   "metadata": {},
   "source": [
    "## 2.2 Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7379fb-af8d-4059-b891-aa7a5472f972",
   "metadata": {},
   "source": [
    "### A - Identification of Informative Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee4daa-9b57-47d3-b04f-135ce3aaa006",
   "metadata": {},
   "source": [
    "Identify which attributes (features) in your data are informative with respect to the target variable (use at least 3 techniques and compare their results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03caeea8-fa35-48ec-b560-d1ca48219a78",
   "metadata": {},
   "source": [
    "#### Variance Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf79d4b-2a6c-4413-9063-2ba305430a0f",
   "metadata": {},
   "source": [
    "Removes features that have a low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34edcd77-3674-41c5-815d-562a881182fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature      variance  selected\n",
      "18    num__O₂ extraction ratio  3.338193e-01      True\n",
      "19                    num__SNR  3.307393e-01      True\n",
      "0                    num__SpO₂  1.150876e-01      True\n",
      "3                      num__RR  1.079148e-01      True\n",
      "2                      num__PI  9.912076e-02      True\n",
      "11               num__Hb level  7.470150e-02      True\n",
      "6                     num__PRV  7.402084e-02      True\n",
      "9   num__Motion/Activity index  7.020677e-02      True\n",
      "10                    num__PVI  7.016539e-02      True\n",
      "16   num__Signal Quality Index  7.001718e-02      True\n",
      "14       num__Blood Flow Index  6.705810e-02      True\n",
      "5                    num__FiO₂  6.676783e-02      True\n",
      "7                      num__BP  6.027917e-02      True\n",
      "17     num__Respiratory effort  5.913989e-02      True\n",
      "4                   num__EtCO₂  5.906535e-02      True\n",
      "8        num__Skin Temperature  5.877173e-02      True\n",
      "1                      num__HR  5.721598e-02      True\n",
      "15  num__PPG waveform features  5.698565e-02      True\n",
      "12                     num__SV  3.277731e-02      True\n",
      "13                     num__CO  2.072527e-32     False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__HR</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__FiO₂</th>\n",
       "      <th>num__PRV</th>\n",
       "      <th>num__BP</th>\n",
       "      <th>num__Skin Temperature</th>\n",
       "      <th>num__Motion/Activity index</th>\n",
       "      <th>num__PVI</th>\n",
       "      <th>num__Hb level</th>\n",
       "      <th>num__SV</th>\n",
       "      <th>num__Blood Flow Index</th>\n",
       "      <th>num__PPG waveform features</th>\n",
       "      <th>num__Signal Quality Index</th>\n",
       "      <th>num__Respiratory effort</th>\n",
       "      <th>num__O₂ extraction ratio</th>\n",
       "      <th>num__SNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.646961</td>\n",
       "      <td>-0.075644</td>\n",
       "      <td>0.597612</td>\n",
       "      <td>0.193844</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>-0.024508</td>\n",
       "      <td>0.057487</td>\n",
       "      <td>0.537581</td>\n",
       "      <td>0.307535</td>\n",
       "      <td>0.287644</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>-0.260123</td>\n",
       "      <td>0.410101</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>-0.092902</td>\n",
       "      <td>-0.203014</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>-0.304962</td>\n",
       "      <td>0.600777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-0.455904</td>\n",
       "      <td>-0.019785</td>\n",
       "      <td>0.415433</td>\n",
       "      <td>-0.548389</td>\n",
       "      <td>-0.109406</td>\n",
       "      <td>0.307762</td>\n",
       "      <td>0.090899</td>\n",
       "      <td>0.213321</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>-0.335959</td>\n",
       "      <td>-0.319867</td>\n",
       "      <td>-0.102764</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.203126</td>\n",
       "      <td>0.073040</td>\n",
       "      <td>-0.215115</td>\n",
       "      <td>0.369021</td>\n",
       "      <td>0.460889</td>\n",
       "      <td>-0.809611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-0.754838</td>\n",
       "      <td>0.058197</td>\n",
       "      <td>0.321418</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.079173</td>\n",
       "      <td>0.545983</td>\n",
       "      <td>-0.182852</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>0.066777</td>\n",
       "      <td>0.632624</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.080655</td>\n",
       "      <td>0.241763</td>\n",
       "      <td>-0.228235</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>0.478461</td>\n",
       "      <td>0.524375</td>\n",
       "      <td>0.233974</td>\n",
       "      <td>-0.592450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.312978</td>\n",
       "      <td>-0.181308</td>\n",
       "      <td>0.151513</td>\n",
       "      <td>-0.183058</td>\n",
       "      <td>-0.008968</td>\n",
       "      <td>0.093358</td>\n",
       "      <td>-0.217889</td>\n",
       "      <td>-0.134459</td>\n",
       "      <td>-0.468115</td>\n",
       "      <td>-0.470503</td>\n",
       "      <td>-0.312215</td>\n",
       "      <td>0.450835</td>\n",
       "      <td>0.461460</td>\n",
       "      <td>-0.462728</td>\n",
       "      <td>-0.201469</td>\n",
       "      <td>0.089030</td>\n",
       "      <td>-0.007263</td>\n",
       "      <td>0.654740</td>\n",
       "      <td>0.553096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.089378</td>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.358835</td>\n",
       "      <td>0.240705</td>\n",
       "      <td>0.373361</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>-0.212242</td>\n",
       "      <td>-0.296770</td>\n",
       "      <td>-0.284371</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>-0.602900</td>\n",
       "      <td>0.547206</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>0.114403</td>\n",
       "      <td>0.245277</td>\n",
       "      <td>0.147463</td>\n",
       "      <td>0.656670</td>\n",
       "      <td>0.758629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__HR   num__PI   num__RR  num__EtCO₂  num__FiO₂  \\\n",
       "108     0.646961 -0.075644  0.597612  0.193844    0.017658  -0.024508   \n",
       "12092  -0.455904 -0.019785  0.415433 -0.548389   -0.109406   0.307762   \n",
       "9658   -0.754838  0.058197  0.321418 -1.000000   -0.079173   0.545983   \n",
       "2929   -0.312978 -0.181308  0.151513 -0.183058   -0.008968   0.093358   \n",
       "10405   0.089378  0.057883  0.358835  0.240705    0.373361   0.007094   \n",
       "\n",
       "       num__PRV   num__BP  num__Skin Temperature  num__Motion/Activity index  \\\n",
       "108    0.057487  0.537581               0.307535                    0.287644   \n",
       "12092  0.090899  0.213321               0.016972                   -0.335959   \n",
       "9658  -0.182852 -0.120784               0.066777                    0.632624   \n",
       "2929  -0.217889 -0.134459              -0.468115                   -0.470503   \n",
       "10405  0.060499 -0.212242              -0.296770                   -0.284371   \n",
       "\n",
       "       num__PVI  num__Hb level   num__SV  num__Blood Flow Index  \\\n",
       "108    0.082924      -0.260123  0.410101              -0.204876   \n",
       "12092 -0.319867      -0.102764  0.351103               0.203126   \n",
       "9658   0.021375       0.080655  0.241763              -0.228235   \n",
       "2929  -0.312215       0.450835  0.461460              -0.462728   \n",
       "10405  0.330900      -0.602900  0.547206              -0.004706   \n",
       "\n",
       "       num__PPG waveform features  num__Signal Quality Index  \\\n",
       "108                     -0.092902                  -0.203014   \n",
       "12092                    0.073040                  -0.215115   \n",
       "9658                     0.013277                   0.478461   \n",
       "2929                    -0.201469                   0.089030   \n",
       "10405                    0.114403                   0.245277   \n",
       "\n",
       "       num__Respiratory effort  num__O₂ extraction ratio  num__SNR  \n",
       "108                   0.442998                 -0.304962  0.600777  \n",
       "12092                 0.369021                  0.460889 -0.809611  \n",
       "9658                  0.524375                  0.233974 -0.592450  \n",
       "2929                 -0.007263                  0.654740  0.553096  \n",
       "10405                 0.147463                  0.656670  0.758629  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    #(\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    #(\"scaler\", StandardScaler()),\n",
    "    (\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='drop').set_output(transform=\"pandas\")),\n",
    "    (\"variance_threshold\", VarianceThreshold(threshold=0.01).set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='drop').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train, y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "select_variance = observation_pipeline.named_steps['variance_threshold']\n",
    "column_transformer = observation_pipeline.named_steps['encode']\n",
    "feature_names = column_transformer.get_feature_names_out()\n",
    "variances = select_variance.variances_\n",
    "variance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'variance': variances,\n",
    "    'selected': select_variance.get_support()\n",
    "})\n",
    "\n",
    "variance_df = variance_df.sort_values(by='variance', ascending=False)\n",
    "\n",
    "print(variance_df)\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32811d41-6b19-4426-96b7-ba64eb7f6fb4",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ecde0-2e4f-4360-934e-da7722ab12a4",
   "metadata": {},
   "source": [
    "Measures the dependency between the variables, higher the output, higher the dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c30a245-706e-40ef-bbe5-f9edd38b97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9684, 22)\n",
      "(9684,)\n",
      "                       feature        score         pvalue  selected\n",
      "3                      num__RR  7698.413244   0.000000e+00      True\n",
      "0                    num__SpO₂  1551.981999  5.776681e-315      True\n",
      "4                   num__EtCO₂   881.097025  2.144124e-185      True\n",
      "2                      num__PI   141.977542   1.658836e-32      True\n",
      "10                    num__PVI   128.573107   1.292298e-29      True\n",
      "7                      num__BP     4.409002   3.577557e-02      True\n",
      "1                      num__HR     2.264801   1.323758e-01      True\n",
      "18    num__O₂ extraction ratio     1.767380   1.837380e-01      True\n",
      "5                    num__FiO₂     1.606365   2.050340e-01      True\n",
      "16   num__Signal Quality Index     1.355852   2.442864e-01      True\n",
      "12                     num__SV     1.194406   2.744698e-01      True\n",
      "14       num__Blood Flow Index     1.053877   3.046414e-01      True\n",
      "9   num__Motion/Activity index     0.542119   4.615736e-01      True\n",
      "15  num__PPG waveform features     0.519227   4.711892e-01      True\n",
      "6                     num__PRV     0.321681   5.706125e-01      True\n",
      "19                    num__SNR     0.311793   5.765950e-01     False\n",
      "8        num__Skin Temperature     0.220217   6.388851e-01     False\n",
      "17     num__Respiratory effort     0.171790   6.785349e-01     False\n",
      "11               num__Hb level     0.061281   8.044879e-01     False\n",
      "13                     num__CO     0.000000   1.000000e+00     False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__HR</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__FiO₂</th>\n",
       "      <th>num__PRV</th>\n",
       "      <th>num__BP</th>\n",
       "      <th>num__Motion/Activity index</th>\n",
       "      <th>num__PVI</th>\n",
       "      <th>num__SV</th>\n",
       "      <th>num__Blood Flow Index</th>\n",
       "      <th>num__PPG waveform features</th>\n",
       "      <th>num__Signal Quality Index</th>\n",
       "      <th>num__O₂ extraction ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.646961</td>\n",
       "      <td>-0.075644</td>\n",
       "      <td>0.597612</td>\n",
       "      <td>0.193844</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>-0.024508</td>\n",
       "      <td>0.057487</td>\n",
       "      <td>0.537581</td>\n",
       "      <td>0.287644</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>0.410101</td>\n",
       "      <td>-0.204876</td>\n",
       "      <td>-0.092902</td>\n",
       "      <td>-0.203014</td>\n",
       "      <td>-0.304962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-0.455904</td>\n",
       "      <td>-0.019785</td>\n",
       "      <td>0.415433</td>\n",
       "      <td>-0.548389</td>\n",
       "      <td>-0.109406</td>\n",
       "      <td>0.307762</td>\n",
       "      <td>0.090899</td>\n",
       "      <td>0.213321</td>\n",
       "      <td>-0.335959</td>\n",
       "      <td>-0.319867</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.203126</td>\n",
       "      <td>0.073040</td>\n",
       "      <td>-0.215115</td>\n",
       "      <td>0.460889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-0.754838</td>\n",
       "      <td>0.058197</td>\n",
       "      <td>0.321418</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.079173</td>\n",
       "      <td>0.545983</td>\n",
       "      <td>-0.182852</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>0.632624</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.241763</td>\n",
       "      <td>-0.228235</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>0.478461</td>\n",
       "      <td>0.233974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.312978</td>\n",
       "      <td>-0.181308</td>\n",
       "      <td>0.151513</td>\n",
       "      <td>-0.183058</td>\n",
       "      <td>-0.008968</td>\n",
       "      <td>0.093358</td>\n",
       "      <td>-0.217889</td>\n",
       "      <td>-0.134459</td>\n",
       "      <td>-0.470503</td>\n",
       "      <td>-0.312215</td>\n",
       "      <td>0.461460</td>\n",
       "      <td>-0.462728</td>\n",
       "      <td>-0.201469</td>\n",
       "      <td>0.089030</td>\n",
       "      <td>0.654740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.089378</td>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.358835</td>\n",
       "      <td>0.240705</td>\n",
       "      <td>0.373361</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.060499</td>\n",
       "      <td>-0.212242</td>\n",
       "      <td>-0.284371</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.547206</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>0.114403</td>\n",
       "      <td>0.245277</td>\n",
       "      <td>0.656670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__HR   num__PI   num__RR  num__EtCO₂  num__FiO₂  \\\n",
       "108     0.646961 -0.075644  0.597612  0.193844    0.017658  -0.024508   \n",
       "12092  -0.455904 -0.019785  0.415433 -0.548389   -0.109406   0.307762   \n",
       "9658   -0.754838  0.058197  0.321418 -1.000000   -0.079173   0.545983   \n",
       "2929   -0.312978 -0.181308  0.151513 -0.183058   -0.008968   0.093358   \n",
       "10405   0.089378  0.057883  0.358835  0.240705    0.373361   0.007094   \n",
       "\n",
       "       num__PRV   num__BP  num__Motion/Activity index  num__PVI   num__SV  \\\n",
       "108    0.057487  0.537581                    0.287644  0.082924  0.410101   \n",
       "12092  0.090899  0.213321                   -0.335959 -0.319867  0.351103   \n",
       "9658  -0.182852 -0.120784                    0.632624  0.021375  0.241763   \n",
       "2929  -0.217889 -0.134459                   -0.470503 -0.312215  0.461460   \n",
       "10405  0.060499 -0.212242                   -0.284371  0.330900  0.547206   \n",
       "\n",
       "       num__Blood Flow Index  num__PPG waveform features  \\\n",
       "108                -0.204876                   -0.092902   \n",
       "12092               0.203126                    0.073040   \n",
       "9658               -0.228235                    0.013277   \n",
       "2929               -0.462728                   -0.201469   \n",
       "10405              -0.004706                    0.114403   \n",
       "\n",
       "       num__Signal Quality Index  num__O₂ extraction ratio  \n",
       "108                    -0.203014                 -0.304962  \n",
       "12092                  -0.215115                  0.460889  \n",
       "9658                    0.478461                  0.233974  \n",
       "2929                    0.089030                  0.654740  \n",
       "10405                   0.245277                  0.656670  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    #(\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    #(\"scaler\", StandardScaler()),\n",
    "    (\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='drop').set_output(transform=\"pandas\")),\n",
    "    (\"select_kbest\", SelectKBest(score_func=f_regression, k=15).set_output(transform=\"pandas\")) \n",
    "\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='drop').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train, y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "select_kbest_step = observation_pipeline.named_steps['select_kbest']\n",
    "mask = select_kbest_step.get_support() \n",
    "column_transformer = observation_pipeline.named_steps['encode']\n",
    "feature_names = column_transformer.get_feature_names_out()\n",
    "scores = select_kbest_step.scores_\n",
    "pvalues = select_kbest_step.pvalues_\n",
    "\n",
    "kbest_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'score': scores,\n",
    "    'pvalue': pvalues,\n",
    "    'selected': mask\n",
    "}).sort_values('score', ascending=False)\n",
    "\n",
    "print(kbest_df)\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dacfe4b-e951-4bdd-a754-b84b5f883628",
   "metadata": {},
   "source": [
    "#### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f2de2c6-1e44-47d3-a1a9-3f6fd2623a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature  selected  rank\n",
      "0                    num__SpO₂      True     1\n",
      "2                      num__PI      True     1\n",
      "3                      num__RR      True     1\n",
      "4                   num__EtCO₂      True     1\n",
      "7                      num__BP      True     1\n",
      "10                    num__PVI     False     2\n",
      "16     num__Respiratory effort     False     3\n",
      "12                     num__SV     False     4\n",
      "11               num__Hb level     False     5\n",
      "13       num__Blood Flow Index     False     6\n",
      "5                    num__FiO₂     False     7\n",
      "15   num__Signal Quality Index     False     8\n",
      "14  num__PPG waveform features     False     9\n",
      "6                     num__PRV     False    10\n",
      "1                      num__HR     False    11\n",
      "8        num__Skin Temperature     False    12\n",
      "9   num__Motion/Activity index     False    13\n",
      "17                    num__SNR     False    14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__SpO₂</th>\n",
       "      <th>num__PI</th>\n",
       "      <th>num__RR</th>\n",
       "      <th>num__EtCO₂</th>\n",
       "      <th>num__BP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.646961</td>\n",
       "      <td>0.597612</td>\n",
       "      <td>0.193844</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>0.537581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>-0.455904</td>\n",
       "      <td>0.415433</td>\n",
       "      <td>-0.548389</td>\n",
       "      <td>-0.109406</td>\n",
       "      <td>0.213321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>-0.754838</td>\n",
       "      <td>0.321418</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.079173</td>\n",
       "      <td>-0.120784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-0.312978</td>\n",
       "      <td>0.151513</td>\n",
       "      <td>-0.183058</td>\n",
       "      <td>-0.008968</td>\n",
       "      <td>-0.134459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>0.089378</td>\n",
       "      <td>0.358835</td>\n",
       "      <td>0.240705</td>\n",
       "      <td>0.373361</td>\n",
       "      <td>-0.212242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__SpO₂   num__PI   num__RR  num__EtCO₂   num__BP\n",
       "108     0.646961  0.597612  0.193844    0.017658  0.537581\n",
       "12092  -0.455904  0.415433 -0.548389   -0.109406  0.213321\n",
       "9658   -0.754838  0.321418 -1.000000   -0.079173 -0.120784\n",
       "2929   -0.312978  0.151513 -0.183058   -0.008968 -0.134459\n",
       "10405   0.089378  0.358835  0.240705    0.373361 -0.212242"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_columns(df):\n",
    "    return df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"power\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    #(\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    #(\"scaler\", StandardScaler()),\n",
    "    (\"scaler\", MinMaxScaler(feature_range=(-1, 1)))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "observation_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=observation_schema)),\n",
    "    (\"ranges\", EnforceValueRanges(ranges=valid_ranges)),\n",
    "    (\"drop_geo\", FunctionTransformer(drop_columns, kw_args={'columns': ['latitude', 'longitude']}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"variance_threshold\", VarianceThreshold(threshold=0.01).set_output(transform=\"pandas\")),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, []),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='drop').set_output(transform=\"pandas\")),\n",
    "    (\"RFE\", RFE(SVR(kernel=\"linear\"), n_features_to_select=5, step=1).set_output(transform=\"pandas\")) \n",
    "\n",
    "])\n",
    "\n",
    "station_pipeline = Pipeline([\n",
    "    (\"schema\", EnforceSchema(schema=station_schema)),\n",
    "    (\"drop_station_and_date\", FunctionTransformer(drop_columns, kw_args={'columns': ['station', 'revision']}, validate=False)),\n",
    "    (\"parse_location\", FunctionTransformer(parse_location, kw_args={'column': 'location'}, validate=False)),\n",
    "    (\"drop_na\", FunctionTransformer(drop_na, kw_args={'how': 'any'}, validate=False)),\n",
    "    (\"encode\", ColumnTransformer([\n",
    "        ('cat', cat_pipeline, ['continent', 'city', 'code']),\n",
    "        ('num', numeric_pipeline, get_numeric_columns)\n",
    "    ], remainder='drop').set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformed_observation = observation_pipeline.fit_transform(X_train, y_train)\n",
    "transformed_station = station_pipeline.fit_transform(pd.read_csv(\"dataset/station.csv\", sep='\\t'))\n",
    "\n",
    "select_rfe = observation_pipeline.named_steps['RFE']\n",
    "mask = select_rfe.get_support() \n",
    "column_transformer = observation_pipeline.named_steps['encode']\n",
    "feature_names = column_transformer.get_feature_names_out()\n",
    "ranks = select_rfe.ranking_\n",
    "\n",
    "rfe_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'selected': mask,\n",
    "    'rank': ranks\n",
    "}).sort_values('rank', ascending=True)\n",
    "\n",
    "print(rfe_df)\n",
    "\n",
    "transformed_observation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa483780-560a-4e32-836b-05c3d640d417",
   "metadata": {},
   "source": [
    "### B - Ranking of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b331286-4b6f-4e33-b219-0ec53994f5a4",
   "metadata": {},
   "source": [
    "Rank the identified features by importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec93b5-049e-40cb-940c-671d53552f10",
   "metadata": {},
   "source": [
    "### C - Justification and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9de70-b409-45bf-a9e7-24e22afdfcdf",
   "metadata": {},
   "source": [
    "Justify your choices/decisions for implementation (i.e., provide documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff557b-b0d8-45dd-939b-f0c7e55a3eab",
   "metadata": {},
   "source": [
    "## 2.3 Reproducibility of Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190199a-1b7d-41fc-9d50-62918d367384",
   "metadata": {},
   "source": [
    "### Code Generalization for Reuse and Pipeline Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7f3b3-fd34-4fe9-ae1b-d57d0a816d9c",
   "metadata": {},
   "source": [
    "Modify your preprocessing code for the training dataset so that it can be reused without further modifications to preprocess the test dataset in a machine learning context. Use the sklearn.pipeline functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
