{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4110b7d-d5cd-4e78-b618-841eac6bf638",
   "metadata": {},
   "source": [
    "# Intelligent Data Analysis Project\n",
    "### Matej Bebej (50%), Marian Kurcina (50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ef770-04f0-4a1b-8968-a093a397df5b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Assignment\n",
    "- Phase 2 - Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e85d8a5-61a7-4bb5-ae86-c78db03585c6",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51d95b-e2d3-416b-bd59-4fb793c70703",
   "metadata": {},
   "source": [
    "Oxygen saturation is a key indicator of the proper functioning of the respiratory and circulatory systems. When its value drops to a critically low level, it may indicate life-threatening conditions such as hypoxemia, respiratory failure, or severe infections. In such cases, immediate intervention is essential. Traditional monitoring is performed using pulse oximeters, which, however, can be affected by noise, motion artifacts, or may have limitations in certain clinical situations.\n",
    "\n",
    "Modern machine learning–based approaches offer the possibility to estimate and predict critical oxygen saturation values with higher accuracy (critical oxygen saturation estimation). Models can utilize multimodal data, such as heart rate, respiratory rate, blood pressure, or sensor signals. By being trained on diverse datasets, it is possible to identify early warning signs of desaturation, filter out noise, and provide timely alerts even before oxygen saturation drops below a safe threshold.\n",
    "\n",
    "The goal of this assignment is to become familiar with the issue of oxygen saturation monitoring, understand the contribution of artificial intelligence, and design a solution that could improve critical care and reduce risks associated with undiagnosed hypoxemia.\n",
    "\n",
    "Each pair of students will work with an assigned dataset starting from Week 2. Your task is to predict the dependent variable “oximetry” (the predicted variable) using machine learning methods. In doing so, you will need to deal with various issues present in the data, such as inconsistent formats, missing values, outliers, and others.\n",
    "\n",
    "The expected outcomes of the project are:\n",
    "\n",
    "- the best-performing machine learning model, and\n",
    "\n",
    "- a data pipeline for building it from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce20ec-579b-4e1f-bd06-44d5324f812e",
   "metadata": {},
   "source": [
    "# Phase 2 – Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe3e813-415c-4498-8873-635a77c81807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateparser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "observation = pd.read_csv(\"dataset/observation.csv\", sep='\\t')\n",
    "patient = pd.read_csv(\"dataset/patient.csv\", sep='\\t')\n",
    "station = pd.read_csv(\"dataset/station.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c9876-3f96-4afe-bbfe-d39cb93b99a2",
   "metadata": {},
   "source": [
    "In this phase, you are expected to carry out data preprocessing for machine learning. The result should be a dataset (CSV or TSV), where each observation is described by one row.\n",
    "Since scikit-learn only works with numerical data, something must be done with the non-numerical data.\n",
    "\n",
    "Ensure the preprocessing is reproducible on both the training and test datasets, so that you can repeat the process multiple times as needed (iteratively).\n",
    "\n",
    "Because preprocessing can change the shape and characteristics of the data, you may need to perform EDA (Exploratory Data Analysis) again as necessary. These techniques will not be graded again, but document any changes in the chosen methods.\n",
    "You can solve data-related issues iteratively across all phases, as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b823b-ecb7-467d-abf2-2af9d3700a6c",
   "metadata": {},
   "source": [
    "## 2.1 Implementation of Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4a40f-837a-42e1-b63e-0ba737031bc6",
   "metadata": {},
   "source": [
    "First we preprocess all data by: \n",
    "- enforcing schemas on each data frame\n",
    "- removing latitude and longitude columns from observation since they are not medical data and have no corelation to oxymetry (as we learned in First Phase of the project - EDA)\n",
    "- removing logical outliers - values which are outside of acceptable range\n",
    "- removing records which have oxymetry missing \n",
    "- removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041761b8-351a-4dc7-8227-333ea88209b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_schema = {\n",
    "    'location':'string',\n",
    "    'code':'string',\n",
    "    'revision':'date',\n",
    "    'station':'string',\n",
    "    'latitude':'float',\n",
    "    'longitude':'float',\n",
    "}\n",
    "observation_schema = {\n",
    "    'SpO₂':'float',\n",
    "    'HR':'float',\n",
    "    'PI':'float',\n",
    "    'RR':'float',\n",
    "    'EtCO₂':'float',\n",
    "    'FiO₂':'float',\n",
    "    'PRV':'float',\n",
    "    'BP':'float',\n",
    "    'Skin Temperature':'float',\n",
    "    'Motion/Activity index':'float',\n",
    "    'PVI':'float',\n",
    "    'Hb level':'float',\n",
    "    'SV':'float',\n",
    "    'CO':'float',\n",
    "    'Blood Flow Index':'float',\n",
    "    'PPG waveform features':'float',\n",
    "    'Signal Quality Index':'float',\n",
    "    'Respiratory effort':'float',\n",
    "    'O₂ extraction ratio':'float',\n",
    "    'SNR':'float',\n",
    "    'oximetry':'int',\n",
    "    'latitude':'float',\n",
    "    'longitude':'float'\n",
    "}\n",
    "patient_schema = {\n",
    "    'residence':'string',              \n",
    "    'current_location':'string',    \n",
    "    'blood_group':'string',          \n",
    "    'job':'string',                 \n",
    "    'mail':'string',                \n",
    "    'user_id':'int',             \n",
    "    'birthdate':'date',           \n",
    "    'company':'string',             \n",
    "    'name':'string',                \n",
    "    'username':'string',            \n",
    "    'ssn':'string',                 \n",
    "    'registration':'date',        \n",
    "    'station_ID':'int'            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a07760-5afc-43d2-9bf3-69ca14ac6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enforce_schema(df, schema):\n",
    "    if schema is None:\n",
    "        return df \n",
    "        \n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    for col, col_type in schema.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        if col_type == 'int':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(int)\n",
    "\n",
    "        elif col_type == 'float':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "\n",
    "        elif col_type == 'numeric':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "        elif col_type == 'date':\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: dateparser.parse(str(x))\n",
    "                if pd.notnull(x) else pd.NaT\n",
    "            )\n",
    "\n",
    "        elif col_type == 'string':\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = df[col].replace('nan', np.nan)\n",
    "\n",
    "        elif col_type == 'bool':\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.lower()\n",
    "                .map({'true': True, 'false': False, '1': True, '0': False})\n",
    "            )\n",
    "\n",
    "        elif col_type == 'category':\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f957a35-c33d-41e2-bd14-d53f67dc7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ranges = {\n",
    "    'SpO₂': (95, 100),\n",
    "    'HR': (60, 100),\n",
    "    'PI': (0.2, 20),\n",
    "    'RR': (12, 20),\n",
    "    'EtCO₂': (35, 45),\n",
    "    'FiO₂': (21, 100),\n",
    "    'PRV': (20, 200),\n",
    "    'BP': (60, 120),\n",
    "    'Skin Temperature': (33, 38),\n",
    "    'Motion/Activity index': None,\n",
    "    'PVI': (10, 20),\n",
    "    'Hb level': (12, 18),\n",
    "    'SV': (60, 100),\n",
    "    'CO': (4, 8),\n",
    "    'Blood Flow Index': None,\n",
    "    'PPG waveform features': None,\n",
    "    'Signal Quality Index': (0, 100),\n",
    "    'Respiratory effort': None,\n",
    "    'O₂ extraction ratio': (0.2, 3),\n",
    "    'SNR': (20, 40)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09f2f6c-4e87-44e2-845b-fe707f9052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_value_ranges(df, ranges):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col, valid_range in ranges.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        if valid_range is None:\n",
    "            continue  # skip features with no range\n",
    "\n",
    "        low, high = valid_range\n",
    "\n",
    "        # Convert to numeric if needed\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Replace anything outside the range with NaN\n",
    "        mask = ~df[col].between(low, high, inclusive='both')\n",
    "        df.loc[mask, col] = np.nan\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b080dbc-e1cd-43a8-8b5f-c69b335ee41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25664\\2426302334.py:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace('nan', np.nan)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpO₂</th>\n",
       "      <th>HR</th>\n",
       "      <th>PI</th>\n",
       "      <th>RR</th>\n",
       "      <th>EtCO₂</th>\n",
       "      <th>FiO₂</th>\n",
       "      <th>PRV</th>\n",
       "      <th>BP</th>\n",
       "      <th>Skin Temperature</th>\n",
       "      <th>Motion/Activity index</th>\n",
       "      <th>...</th>\n",
       "      <th>CO</th>\n",
       "      <th>Blood Flow Index</th>\n",
       "      <th>PPG waveform features</th>\n",
       "      <th>Signal Quality Index</th>\n",
       "      <th>Respiratory effort</th>\n",
       "      <th>O₂ extraction ratio</th>\n",
       "      <th>SNR</th>\n",
       "      <th>oximetry</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.511604</td>\n",
       "      <td>67.597663</td>\n",
       "      <td>14.451123</td>\n",
       "      <td>17.461063</td>\n",
       "      <td>41.262037</td>\n",
       "      <td>87.821291</td>\n",
       "      <td>126.965235</td>\n",
       "      <td>109.471152</td>\n",
       "      <td>35.650826</td>\n",
       "      <td>11.429092</td>\n",
       "      <td>...</td>\n",
       "      <td>4.004591</td>\n",
       "      <td>44.065731</td>\n",
       "      <td>36.604550</td>\n",
       "      <td>69.140438</td>\n",
       "      <td>57.097309</td>\n",
       "      <td>0.210117</td>\n",
       "      <td>33.584512</td>\n",
       "      <td>1</td>\n",
       "      <td>19.64745</td>\n",
       "      <td>-102.04897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.113516</td>\n",
       "      <td>72.872900</td>\n",
       "      <td>4.699563</td>\n",
       "      <td>17.231104</td>\n",
       "      <td>40.220086</td>\n",
       "      <td>64.283914</td>\n",
       "      <td>139.509502</td>\n",
       "      <td>100.943658</td>\n",
       "      <td>35.313317</td>\n",
       "      <td>11.188645</td>\n",
       "      <td>...</td>\n",
       "      <td>4.014983</td>\n",
       "      <td>36.498878</td>\n",
       "      <td>61.305805</td>\n",
       "      <td>50.733704</td>\n",
       "      <td>61.220158</td>\n",
       "      <td>0.293664</td>\n",
       "      <td>30.528645</td>\n",
       "      <td>1</td>\n",
       "      <td>28.15112</td>\n",
       "      <td>-82.46148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.623248</td>\n",
       "      <td>81.418306</td>\n",
       "      <td>12.056504</td>\n",
       "      <td>16.832868</td>\n",
       "      <td>39.953184</td>\n",
       "      <td>77.164206</td>\n",
       "      <td>104.396821</td>\n",
       "      <td>107.401302</td>\n",
       "      <td>36.017931</td>\n",
       "      <td>8.980842</td>\n",
       "      <td>...</td>\n",
       "      <td>4.083922</td>\n",
       "      <td>52.803185</td>\n",
       "      <td>49.432273</td>\n",
       "      <td>41.841466</td>\n",
       "      <td>57.554854</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>22.357337</td>\n",
       "      <td>1</td>\n",
       "      <td>-38.16604</td>\n",
       "      <td>145.13643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.821905</td>\n",
       "      <td>69.356881</td>\n",
       "      <td>11.044410</td>\n",
       "      <td>14.876013</td>\n",
       "      <td>38.765113</td>\n",
       "      <td>59.296747</td>\n",
       "      <td>180.845101</td>\n",
       "      <td>106.786082</td>\n",
       "      <td>35.433515</td>\n",
       "      <td>9.952747</td>\n",
       "      <td>...</td>\n",
       "      <td>4.006763</td>\n",
       "      <td>52.800923</td>\n",
       "      <td>68.710875</td>\n",
       "      <td>47.524447</td>\n",
       "      <td>48.971775</td>\n",
       "      <td>0.288125</td>\n",
       "      <td>25.886190</td>\n",
       "      <td>0</td>\n",
       "      <td>40.63316</td>\n",
       "      <td>-74.13653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.523262</td>\n",
       "      <td>70.686313</td>\n",
       "      <td>5.963887</td>\n",
       "      <td>16.933547</td>\n",
       "      <td>41.470854</td>\n",
       "      <td>66.145767</td>\n",
       "      <td>111.525074</td>\n",
       "      <td>108.354216</td>\n",
       "      <td>35.258355</td>\n",
       "      <td>10.619401</td>\n",
       "      <td>...</td>\n",
       "      <td>4.008813</td>\n",
       "      <td>25.406073</td>\n",
       "      <td>33.993656</td>\n",
       "      <td>60.323832</td>\n",
       "      <td>54.807359</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>20.836752</td>\n",
       "      <td>1</td>\n",
       "      <td>4.88441</td>\n",
       "      <td>101.96857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SpO₂         HR         PI         RR      EtCO₂       FiO₂  \\\n",
       "0  96.511604  67.597663  14.451123  17.461063  41.262037  87.821291   \n",
       "1  98.113516  72.872900   4.699563  17.231104  40.220086  64.283914   \n",
       "2  98.623248  81.418306  12.056504  16.832868  39.953184  77.164206   \n",
       "3  96.821905  69.356881  11.044410  14.876013  38.765113  59.296747   \n",
       "4  98.523262  70.686313   5.963887  16.933547  41.470854  66.145767   \n",
       "\n",
       "          PRV          BP  Skin Temperature  Motion/Activity index  ...  \\\n",
       "0  126.965235  109.471152         35.650826              11.429092  ...   \n",
       "1  139.509502  100.943658         35.313317              11.188645  ...   \n",
       "2  104.396821  107.401302         36.017931               8.980842  ...   \n",
       "3  180.845101  106.786082         35.433515               9.952747  ...   \n",
       "4  111.525074  108.354216         35.258355              10.619401  ...   \n",
       "\n",
       "         CO  Blood Flow Index  PPG waveform features  Signal Quality Index  \\\n",
       "0  4.004591         44.065731              36.604550             69.140438   \n",
       "1  4.014983         36.498878              61.305805             50.733704   \n",
       "2  4.083922         52.803185              49.432273             41.841466   \n",
       "3  4.006763         52.800923              68.710875             47.524447   \n",
       "4  4.008813         25.406073              33.993656             60.323832   \n",
       "\n",
       "   Respiratory effort  O₂ extraction ratio        SNR  oximetry  latitude  \\\n",
       "0           57.097309             0.210117  33.584512         1  19.64745   \n",
       "1           61.220158             0.293664  30.528645         1  28.15112   \n",
       "2           57.554854             0.232518  22.357337         1 -38.16604   \n",
       "3           48.971775             0.288125  25.886190         0  40.63316   \n",
       "4           54.807359             0.295855  20.836752         1   4.88441   \n",
       "\n",
       "   longitude  \n",
       "0 -102.04897  \n",
       "1  -82.46148  \n",
       "2  145.13643  \n",
       "3  -74.13653  \n",
       "4  101.96857  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = enforce_schema(observation, observation_schema)\n",
    "observation = enforce_value_ranges(observation, valid_ranges)\n",
    "\n",
    "station = enforce_schema(station, station_schema)\n",
    "\n",
    "patient = enforce_schema(patient, patient_schema)\n",
    "observation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4951f79e-6cf0-4674-a306-d5a4745c2171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpO₂</th>\n",
       "      <th>HR</th>\n",
       "      <th>PI</th>\n",
       "      <th>RR</th>\n",
       "      <th>EtCO₂</th>\n",
       "      <th>FiO₂</th>\n",
       "      <th>PRV</th>\n",
       "      <th>BP</th>\n",
       "      <th>Skin Temperature</th>\n",
       "      <th>Motion/Activity index</th>\n",
       "      <th>...</th>\n",
       "      <th>Hb level</th>\n",
       "      <th>SV</th>\n",
       "      <th>CO</th>\n",
       "      <th>Blood Flow Index</th>\n",
       "      <th>PPG waveform features</th>\n",
       "      <th>Signal Quality Index</th>\n",
       "      <th>Respiratory effort</th>\n",
       "      <th>O₂ extraction ratio</th>\n",
       "      <th>SNR</th>\n",
       "      <th>oximetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.511604</td>\n",
       "      <td>67.597663</td>\n",
       "      <td>14.451123</td>\n",
       "      <td>17.461063</td>\n",
       "      <td>41.262037</td>\n",
       "      <td>87.821291</td>\n",
       "      <td>126.965235</td>\n",
       "      <td>109.471152</td>\n",
       "      <td>35.650826</td>\n",
       "      <td>11.429092</td>\n",
       "      <td>...</td>\n",
       "      <td>13.922029</td>\n",
       "      <td>83.801243</td>\n",
       "      <td>4.004591</td>\n",
       "      <td>44.065731</td>\n",
       "      <td>36.604550</td>\n",
       "      <td>69.140438</td>\n",
       "      <td>57.097309</td>\n",
       "      <td>0.210117</td>\n",
       "      <td>33.584512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.113516</td>\n",
       "      <td>72.872900</td>\n",
       "      <td>4.699563</td>\n",
       "      <td>17.231104</td>\n",
       "      <td>40.220086</td>\n",
       "      <td>64.283914</td>\n",
       "      <td>139.509502</td>\n",
       "      <td>100.943658</td>\n",
       "      <td>35.313317</td>\n",
       "      <td>11.188645</td>\n",
       "      <td>...</td>\n",
       "      <td>16.116704</td>\n",
       "      <td>78.047479</td>\n",
       "      <td>4.014983</td>\n",
       "      <td>36.498878</td>\n",
       "      <td>61.305805</td>\n",
       "      <td>50.733704</td>\n",
       "      <td>61.220158</td>\n",
       "      <td>0.293664</td>\n",
       "      <td>30.528645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.623248</td>\n",
       "      <td>81.418306</td>\n",
       "      <td>12.056504</td>\n",
       "      <td>16.832868</td>\n",
       "      <td>39.953184</td>\n",
       "      <td>77.164206</td>\n",
       "      <td>104.396821</td>\n",
       "      <td>107.401302</td>\n",
       "      <td>36.017931</td>\n",
       "      <td>8.980842</td>\n",
       "      <td>...</td>\n",
       "      <td>13.672567</td>\n",
       "      <td>86.640923</td>\n",
       "      <td>4.083922</td>\n",
       "      <td>52.803185</td>\n",
       "      <td>49.432273</td>\n",
       "      <td>41.841466</td>\n",
       "      <td>57.554854</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>22.357337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.821905</td>\n",
       "      <td>69.356881</td>\n",
       "      <td>11.044410</td>\n",
       "      <td>14.876013</td>\n",
       "      <td>38.765113</td>\n",
       "      <td>59.296747</td>\n",
       "      <td>180.845101</td>\n",
       "      <td>106.786082</td>\n",
       "      <td>35.433515</td>\n",
       "      <td>9.952747</td>\n",
       "      <td>...</td>\n",
       "      <td>14.955819</td>\n",
       "      <td>87.187544</td>\n",
       "      <td>4.006763</td>\n",
       "      <td>52.800923</td>\n",
       "      <td>68.710875</td>\n",
       "      <td>47.524447</td>\n",
       "      <td>48.971775</td>\n",
       "      <td>0.288125</td>\n",
       "      <td>25.886190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.523262</td>\n",
       "      <td>70.686313</td>\n",
       "      <td>5.963887</td>\n",
       "      <td>16.933547</td>\n",
       "      <td>41.470854</td>\n",
       "      <td>66.145767</td>\n",
       "      <td>111.525074</td>\n",
       "      <td>108.354216</td>\n",
       "      <td>35.258355</td>\n",
       "      <td>10.619401</td>\n",
       "      <td>...</td>\n",
       "      <td>15.016218</td>\n",
       "      <td>87.354000</td>\n",
       "      <td>4.008813</td>\n",
       "      <td>25.406073</td>\n",
       "      <td>33.993656</td>\n",
       "      <td>60.323832</td>\n",
       "      <td>54.807359</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>20.836752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SpO₂         HR         PI         RR      EtCO₂       FiO₂  \\\n",
       "0  96.511604  67.597663  14.451123  17.461063  41.262037  87.821291   \n",
       "1  98.113516  72.872900   4.699563  17.231104  40.220086  64.283914   \n",
       "2  98.623248  81.418306  12.056504  16.832868  39.953184  77.164206   \n",
       "3  96.821905  69.356881  11.044410  14.876013  38.765113  59.296747   \n",
       "4  98.523262  70.686313   5.963887  16.933547  41.470854  66.145767   \n",
       "\n",
       "          PRV          BP  Skin Temperature  Motion/Activity index  ...  \\\n",
       "0  126.965235  109.471152         35.650826              11.429092  ...   \n",
       "1  139.509502  100.943658         35.313317              11.188645  ...   \n",
       "2  104.396821  107.401302         36.017931               8.980842  ...   \n",
       "3  180.845101  106.786082         35.433515               9.952747  ...   \n",
       "4  111.525074  108.354216         35.258355              10.619401  ...   \n",
       "\n",
       "    Hb level         SV        CO  Blood Flow Index  PPG waveform features  \\\n",
       "0  13.922029  83.801243  4.004591         44.065731              36.604550   \n",
       "1  16.116704  78.047479  4.014983         36.498878              61.305805   \n",
       "2  13.672567  86.640923  4.083922         52.803185              49.432273   \n",
       "3  14.955819  87.187544  4.006763         52.800923              68.710875   \n",
       "4  15.016218  87.354000  4.008813         25.406073              33.993656   \n",
       "\n",
       "   Signal Quality Index  Respiratory effort  O₂ extraction ratio        SNR  \\\n",
       "0             69.140438           57.097309             0.210117  33.584512   \n",
       "1             50.733704           61.220158             0.293664  30.528645   \n",
       "2             41.841466           57.554854             0.232518  22.357337   \n",
       "3             47.524447           48.971775             0.288125  25.886190   \n",
       "4             60.323832           54.807359             0.295855  20.836752   \n",
       "\n",
       "   oximetry  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = observation.drop(columns=['latitude', 'longitude'], errors='ignore')\n",
    "observation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756433fd-70e1-45ed-a353-cea0aedb4e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "null_oximetry_rows = observation[observation['oximetry'].isna()]\n",
    "print(len(null_oximetry_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3928b32-b5d4-4769-979c-eed59ea2fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = observation.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab7e746-79f1-4f34-9d5a-a37976760c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parse(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    split_cols = df['location'].astype(str).str.split('/', n=1, expand=True)\n",
    "\n",
    "    df['continent'] = split_cols[0].str.strip()\n",
    "    df['city'] = split_cols[1].str.strip()\n",
    "\n",
    "    df = df.drop(columns=['location'])\n",
    "\n",
    "    return df\n",
    "\n",
    "station = Parse(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bb233-dc76-4391-b893-beeb833cb867",
   "metadata": {},
   "source": [
    "### A - Train–Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db092e00-b43f-4e5d-b52a-c3d53baa35ab",
   "metadata": {},
   "source": [
    "Split the data into training and test sets according to your predefined ratio. Continue working only with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc43d6c4-18be-4e11-bb8e-cae030f9a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9542, 20)\n",
      "X_test shape: (2386, 20)\n",
      "y_train shape: (9542,)\n",
      "y_test shape: (2386,)\n"
     ]
    }
   ],
   "source": [
    "X = observation.drop(columns=['oximetry'])  \n",
    "y = observation['oximetry']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,   \n",
    "    random_state=42, \n",
    "    stratify=y       \n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef1b03-c01e-4000-91bf-32d9fab0d755",
   "metadata": {},
   "source": [
    "We split data into train and test parts, with 20% of observation data being test data () and 80% being train data ()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae639950-ff60-4e42-8b56-ead60d49b0d5",
   "metadata": {},
   "source": [
    "### B - Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb66f96-d6da-4c4d-8eb3-573907f45926",
   "metadata": {},
   "source": [
    "Transform the data into a format suitable for machine learning, i.e. each observation must be described by one row, and each attribute must be numeric.\n",
    "Iteratively integrate preprocessing steps from Phase 1 as part of a unified process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc8fab-112d-45d9-9277-9bad261b9746",
   "metadata": {},
   "source": [
    "For observation dataset there are no string or category features, therefore we will show encoding on station dataset. In pipeline we will still call encoding but it will have no effect.\n",
    "\n",
    "We also ignore revision column and station column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a764906-9ae6-42f2-b6f4-0e90ba24edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent_Africa</th>\n",
       "      <th>continent_America</th>\n",
       "      <th>continent_Asia</th>\n",
       "      <th>continent_Atlantic</th>\n",
       "      <th>continent_Australia</th>\n",
       "      <th>continent_Europe</th>\n",
       "      <th>continent_Indian</th>\n",
       "      <th>continent_Pacific</th>\n",
       "      <th>city_Abidjan</th>\n",
       "      <th>city_Accra</th>\n",
       "      <th>...</th>\n",
       "      <th>code_UA</th>\n",
       "      <th>code_US</th>\n",
       "      <th>code_UY</th>\n",
       "      <th>code_UZ</th>\n",
       "      <th>code_VE</th>\n",
       "      <th>code_VU</th>\n",
       "      <th>code_YE</th>\n",
       "      <th>code_ZA</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363461</td>\n",
       "      <td>-0.206644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.869177</td>\n",
       "      <td>-1.111640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.091983</td>\n",
       "      <td>1.123546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388231</td>\n",
       "      <td>-1.374503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816796</td>\n",
       "      <td>-0.001454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   continent_Africa  continent_America  continent_Asia  continent_Atlantic  \\\n",
       "0                 0                  0               0                   0   \n",
       "1                 0                  1               0                   0   \n",
       "2                 0                  0               1                   0   \n",
       "3                 0                  1               0                   0   \n",
       "4                 0                  0               0                   0   \n",
       "\n",
       "   continent_Australia  continent_Europe  continent_Indian  continent_Pacific  \\\n",
       "0                    0                 1                 0                  0   \n",
       "1                    0                 0                 0                  0   \n",
       "2                    0                 0                 0                  0   \n",
       "3                    0                 0                 0                  0   \n",
       "4                    0                 1                 0                  0   \n",
       "\n",
       "   city_Abidjan  city_Accra  ...  code_UA  code_US  code_UY  code_UZ  code_VE  \\\n",
       "0             0           0  ...        0        0        0        0        0   \n",
       "1             0           0  ...        0        0        0        0        0   \n",
       "2             0           0  ...        0        0        0        0        0   \n",
       "3             0           0  ...        0        1        0        0        0   \n",
       "4             0           0  ...        0        0        0        0        0   \n",
       "\n",
       "   code_VU  code_YE  code_ZA  latitude  longitude  \n",
       "0        0        0        0  0.363461  -0.206644  \n",
       "1        0        0        0 -0.869177  -1.111640  \n",
       "2        0        0        0 -0.091983   1.123546  \n",
       "3        0        0        0  0.388231  -1.374503  \n",
       "4        0        0        0  0.816796  -0.001454  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_cleaned = station.drop(columns=['revision', 'station'], errors='ignore')\n",
    "\n",
    "categorical_cols = ['continent', 'city', 'code']\n",
    "numeric_cols = station.select_dtypes(include=['number']).columns.difference(categorical_cols)\n",
    "\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore', dtype=int))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "\n",
    "processed = preprocessor.fit_transform(station)\n",
    "\n",
    "encoded_cols = preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "processed_df = pd.DataFrame(processed, columns=list(encoded_cols) + list(numeric_cols), index=station.index)\n",
    "\n",
    "for col in encoded_cols:\n",
    "    processed_df[col] = processed_df[col].astype(int)\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0307e7-086a-42b6-a078-9a01d1619b39",
   "metadata": {},
   "source": [
    "### C - Feature Scaling and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c29ca-ac4a-4bed-8aca-721c4916c769",
   "metadata": {},
   "source": [
    "Transform the dataset attributes for machine learning using at least the following techniques:\n",
    "\n",
    "- Scaling (2 techniques)\n",
    "- Transformers (2 techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8b512-ae65-4923-b382-c2cba6c23ceb",
   "metadata": {},
   "source": [
    "### D - Justification and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d28cc5-25af-4025-b8ee-366d9461eb9c",
   "metadata": {},
   "source": [
    "Justify your choices/decisions for implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9339e-5c24-414f-858d-500c944d687d",
   "metadata": {},
   "source": [
    "## 2.2 Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7379fb-af8d-4059-b891-aa7a5472f972",
   "metadata": {},
   "source": [
    "### A - Identification of Informative Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee4daa-9b57-47d3-b04f-135ce3aaa006",
   "metadata": {},
   "source": [
    "Identify which attributes (features) in your data are informative with respect to the target variable (use at least 3 techniques and compare their results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa483780-560a-4e32-836b-05c3d640d417",
   "metadata": {},
   "source": [
    "### B - Ranking of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b331286-4b6f-4e33-b219-0ec53994f5a4",
   "metadata": {},
   "source": [
    "Rank the identified features by importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec93b5-049e-40cb-940c-671d53552f10",
   "metadata": {},
   "source": [
    "### C - Justification and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9de70-b409-45bf-a9e7-24e22afdfcdf",
   "metadata": {},
   "source": [
    "Justify your choices/decisions for implementation (i.e., provide documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff557b-b0d8-45dd-939b-f0c7e55a3eab",
   "metadata": {},
   "source": [
    "## 2.3 Reproducibility of Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190199a-1b7d-41fc-9d50-62918d367384",
   "metadata": {},
   "source": [
    "### Code Generalization for Reuse and Pipeline Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7f3b3-fd34-4fe9-ae1b-d57d0a816d9c",
   "metadata": {},
   "source": [
    "Modify your preprocessing code for the training dataset so that it can be reused without further modifications to preprocess the test dataset in a machine learning context. Use the sklearn.pipeline functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
