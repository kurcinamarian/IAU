{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45855b6-3ca7-4a3e-9224-226caf0bcb5d",
   "metadata": {},
   "source": [
    "nacitanie dat, spojenie new_obesrvation s new_station\n",
    "rozdelenie na trainig data a testing data casti\n",
    "vsetky atribute normlaizovat aby boli numericke -> vhodne pre ML (pricom kategoricke features  budu continenty, vynechavame staty a mesta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d0ee9e2-19a1-4f30-be0c-08a678a5e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75399cc2-3815-4f69-b969-0faee8c8e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseLocation:\n",
    "    def __init__(self, column='location'):\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "\n",
    "        if self.column not in df.columns:\n",
    "            raise ValueError(f\"Column '{self.column}' not found in DataFrame.\")\n",
    "\n",
    "        split_cols = df[self.column].astype(str).str.split('/', n=1, expand=True)\n",
    "\n",
    "        df['continent'] = split_cols[0].str.strip()\n",
    "        df['city'] = split_cols[1].str.strip()\n",
    "\n",
    "        df = df.drop(columns=[self.column])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3c28e28-d286-4a01-9b00-9cabe4fa542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clean:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        for col in df.select_dtypes('object').columns:\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.strip()\n",
    "                .str.lower()\n",
    "                .str.replace(r'[^a-z0-9\\s,.-]', '', regex=True)\n",
    "            )\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc05f28a-e299-452b-a58e-304f36903700",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures:\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df.drop(columns=self.columns, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1941c4cf-5b7a-4fee-ba24-4ce269939785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveDuplicates:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def transform(self, df):\n",
    "        return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a79dd38d-32a7-4a60-886f-f4c8c3934fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddFromTable:\n",
    "    def __init__(self, data, condition, columns=None):\n",
    "        self.data = data\n",
    "        if isinstance(condition, str):\n",
    "            self.condition = [condition]\n",
    "        else:\n",
    "            self.condition = condition\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        right = self.data.copy()\n",
    "\n",
    "        cols_to_use = self.condition.copy()\n",
    "        if self.columns:\n",
    "            cols_to_use += [c for c in self.columns if c in right.columns]\n",
    "\n",
    "        right = right[cols_to_use]\n",
    "        return df.merge(right, on=self.condition, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbffb268-939a-454b-8e55-5c7b22d2e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealWithNull:\n",
    "    def __init__(self, remove=None, replace=None, replace_method=None):\n",
    "        self.remove = remove\n",
    "        self.replace = replace\n",
    "        self.replace_method = replace_method\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        if self.remove:\n",
    "            df = df.dropna(subset=self.remove)\n",
    "        if self.replace and self.replace_method is not None:\n",
    "            for col in self.replace:\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                method = self.replace_method\n",
    "                if method == \"mean\":\n",
    "                    df[col] = df[col].fillna(df[col].mean())\n",
    "                elif method == \"median\":\n",
    "                    df[col] = df[col].fillna(df[col].median())\n",
    "                elif method == \"mode\":\n",
    "                    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "                else:\n",
    "                    df[col] = df[col].fillna(method)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a14badcc-e423-4281-9731-02a00c4895da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealWithOutliers:\n",
    "    def __init__(self, IQR=None, cap=None, cap_t=None):\n",
    "        self.IQR = IQR\n",
    "        self.cap = cap\n",
    "        self.cap_t = cap_t\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "\n",
    "        if self.IQR:\n",
    "            for col in self.IQR:\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "\n",
    "                lower = Q1 - 1.5 * IQR\n",
    "                upper = Q3 + 1.5 * IQR\n",
    "\n",
    "                df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "        if self.cap and self.cap_t:\n",
    "            low_p, high_p = self.cap_t, 100 - self.cap_t\n",
    "\n",
    "            for col in self.cap:\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "\n",
    "                lower = np.percentile(df[col].dropna(), low_p)\n",
    "                upper = np.percentile(df[col].dropna(), high_p)\n",
    "\n",
    "                df[col] = np.clip(df[col], lower, upper)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d66260b4-7e25-4b40-9805-3c2e56f235ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f8d6dab-92de-45e0-ad25-016588b588ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class ExtractFeatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "897af8c9-5ea7-4d20-8ab8-75c0e034250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class EnforceSchema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61e8a948-0b4b-47d3-b769-839b1172ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "\n",
    "    def enforce_schema(self, df, schema):\n",
    "        df = df.copy()\n",
    "\n",
    "        for col, col_type in schema.items():\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            if col_type == 'int':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype(int)\n",
    "\n",
    "            elif col_type == 'float':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "\n",
    "            elif col_type == 'numeric':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "            elif col_type == 'date':\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: dateparser.parse(str(x))\n",
    "                    if pd.notnull(x) else pd.NaT\n",
    "                )\n",
    "\n",
    "            elif col_type == 'string':\n",
    "                df[col] = df[col].astype(str)\n",
    "                df[col] = df[col].replace('nan', np.nan)\n",
    "\n",
    "            elif col_type == 'bool':\n",
    "                df[col] = (\n",
    "                    df[col]\n",
    "                    .astype(str)\n",
    "                    .str.lower()\n",
    "                    .map({'true': True, 'false': False, '1': True, '0': False})\n",
    "                )\n",
    "\n",
    "            elif col_type == 'category':\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def run(self, data, schema=None):\n",
    "\n",
    "        if schema is not None:\n",
    "            data = self.enforce_schema(data, schema)\n",
    "        \n",
    "        for step in self.steps:\n",
    "            data = step.transform(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4137d4bb-5a92-4a93-a849-a1c9dab53892",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1_station = Pipeline([\n",
    "    ParseLocation(),\n",
    "    DropFeatures(columns=['revision']),\n",
    "    Clean(),\n",
    "    RemoveDuplicates(),\n",
    "])\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    AddFromTable(data=station_cleaned,condition=['latitude', 'longitude'],columns=['station','code','continent','city']),\n",
    "    Clean(),\n",
    "    RemoveDuplicates(),\n",
    "    DealWithNull(remove=[\n",
    "                        'oximetry'],\n",
    "                 replace=[\n",
    "                         'SpO₂', 'HR', 'PI', 'RR', 'EtCO₂', 'FiO₂',\n",
    "                         'PRV', 'BP', 'Skin Temperature', 'Motion/Activity index',\n",
    "                         'PVI', 'Hb level', 'SV', 'CO', 'Blood Flow Index','PPG waveform features',\n",
    "                         'Signal Quality Index', 'Respiratory effort', 'O₂ extraction ratio', 'SNR'\n",
    "                 ],\n",
    "                 replace_method= \"mean\"),\n",
    "    DealWithOutliers(IQR= [],\n",
    "                     cap=[\n",
    "                         'SpO₂', 'HR', 'PI', 'RR', 'EtCO₂', 'FiO₂',\n",
    "                         'PRV', 'BP', 'Skin Temperature', 'Motion/Activity index',\n",
    "                         'PVI', 'Hb level', 'SV', 'CO', 'Blood Flow Index','PPG waveform features',\n",
    "                         'Signal Quality Index', 'Respiratory effort', 'O₂ extraction ratio', 'SNR'\n",
    "                     ],\n",
    "                     cap_t= 5),\n",
    "    #Preprocess(encode= ,transform=, scale= ),\n",
    "    DropFeatures(columns=['latitude', 'longitude']),\n",
    "    #SelectFeatures(column=),\n",
    "    RemoveDuplicates()            \n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    #Clean()\n",
    "    #RemoveDuplicates(),\n",
    "    #DealWithNull(remove= ,replace= ,replace_method= ),\n",
    "    #DealWithOutliers(IQR= ,cap= ,cap_t= ),\n",
    "    #Preprocess(encode= ,transform=, scale= ),\n",
    "    #DropFeatures(columns=)\n",
    "    #ExtractFeatures(column=),\n",
    "    #RemoveDuplicates()            \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "187356c7-ec03-4ec0-b37b-5acdc7cc0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_schema = {\n",
    "    'location':'string',\n",
    "    'code':'string',\n",
    "    'revision':'date',\n",
    "    'station':'string',\n",
    "    'latitude':'float',\n",
    "    'longitude':'float',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e71ec143-4e6b-499e-a85d-8a8f0d1c5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_schema = {\n",
    "    'SpO₂':'float',\n",
    "    'HR':'float',\n",
    "    'PI':'float',\n",
    "    'RR':'float',\n",
    "    'EtCO₂':'float',\n",
    "    'FiO₂':'float',\n",
    "    'PRV':'float',\n",
    "    'BP':'float',\n",
    "    'Skin Temperature':'float',\n",
    "    'Motion/Activity index':'float',\n",
    "    'PVI':'float',\n",
    "    'Hb level':'float',\n",
    "    'SV':'float',\n",
    "    'CO':'float',\n",
    "    'Blood Flow Index':'float',\n",
    "    'PPG waveform features':'float',\n",
    "    'Signal Quality Index':'float',\n",
    "    'Respiratory effort':'float',\n",
    "    'O₂ extraction ratio':'float',\n",
    "    'SNR':'float',\n",
    "    'oximetry':'int',\n",
    "    'latitude':'float',\n",
    "    'longitude':'float'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca200582-7107-40f0-94b3-4a37e746a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = pd.read_csv(\"dataset/observation.csv\", sep='\\t')\n",
    "station = pd.read_csv(\"dataset/station.csv\", sep='\\t')\n",
    "\n",
    "station_cleaned = pipeline1_station.run(station, station_schema)\n",
    "df_cleaned = pipeline1.run(observation, observation_schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ddf85756-a741-4bdd-9137-250b75b91f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpO₂</th>\n",
       "      <th>HR</th>\n",
       "      <th>PI</th>\n",
       "      <th>RR</th>\n",
       "      <th>EtCO₂</th>\n",
       "      <th>FiO₂</th>\n",
       "      <th>PRV</th>\n",
       "      <th>BP</th>\n",
       "      <th>Skin Temperature</th>\n",
       "      <th>Motion/Activity index</th>\n",
       "      <th>...</th>\n",
       "      <th>PPG waveform features</th>\n",
       "      <th>Signal Quality Index</th>\n",
       "      <th>Respiratory effort</th>\n",
       "      <th>O₂ extraction ratio</th>\n",
       "      <th>SNR</th>\n",
       "      <th>oximetry</th>\n",
       "      <th>station</th>\n",
       "      <th>code</th>\n",
       "      <th>continent</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.511604</td>\n",
       "      <td>70.263434</td>\n",
       "      <td>14.451123</td>\n",
       "      <td>17.461063</td>\n",
       "      <td>41.262037</td>\n",
       "      <td>78.519798</td>\n",
       "      <td>126.965235</td>\n",
       "      <td>109.471152</td>\n",
       "      <td>35.650826</td>\n",
       "      <td>11.429092</td>\n",
       "      <td>...</td>\n",
       "      <td>36.604550</td>\n",
       "      <td>69.140438</td>\n",
       "      <td>57.097309</td>\n",
       "      <td>0.210117</td>\n",
       "      <td>33.584512</td>\n",
       "      <td>1</td>\n",
       "      <td>paracho de verduzco</td>\n",
       "      <td>mx</td>\n",
       "      <td>america</td>\n",
       "      <td>mexicocity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.113516</td>\n",
       "      <td>72.872900</td>\n",
       "      <td>4.699563</td>\n",
       "      <td>17.231104</td>\n",
       "      <td>40.220086</td>\n",
       "      <td>64.283914</td>\n",
       "      <td>139.509502</td>\n",
       "      <td>100.943658</td>\n",
       "      <td>35.313317</td>\n",
       "      <td>11.188645</td>\n",
       "      <td>...</td>\n",
       "      <td>61.305805</td>\n",
       "      <td>50.733704</td>\n",
       "      <td>61.220158</td>\n",
       "      <td>0.293664</td>\n",
       "      <td>30.528645</td>\n",
       "      <td>1</td>\n",
       "      <td>lutz</td>\n",
       "      <td>us</td>\n",
       "      <td>america</td>\n",
       "      <td>newyork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.623248</td>\n",
       "      <td>81.418306</td>\n",
       "      <td>12.056504</td>\n",
       "      <td>16.832868</td>\n",
       "      <td>39.953184</td>\n",
       "      <td>77.164206</td>\n",
       "      <td>104.396821</td>\n",
       "      <td>107.401302</td>\n",
       "      <td>36.017931</td>\n",
       "      <td>8.980842</td>\n",
       "      <td>...</td>\n",
       "      <td>49.432273</td>\n",
       "      <td>41.841466</td>\n",
       "      <td>57.554854</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>22.357337</td>\n",
       "      <td>1</td>\n",
       "      <td>frankston south</td>\n",
       "      <td>au</td>\n",
       "      <td>australia</td>\n",
       "      <td>melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.821905</td>\n",
       "      <td>70.263434</td>\n",
       "      <td>11.044410</td>\n",
       "      <td>14.876013</td>\n",
       "      <td>38.765113</td>\n",
       "      <td>59.296747</td>\n",
       "      <td>147.612105</td>\n",
       "      <td>106.786082</td>\n",
       "      <td>35.433515</td>\n",
       "      <td>9.952747</td>\n",
       "      <td>...</td>\n",
       "      <td>68.710875</td>\n",
       "      <td>47.524447</td>\n",
       "      <td>48.971775</td>\n",
       "      <td>0.288125</td>\n",
       "      <td>25.886190</td>\n",
       "      <td>0</td>\n",
       "      <td>port richmond</td>\n",
       "      <td>us</td>\n",
       "      <td>america</td>\n",
       "      <td>newyork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.523262</td>\n",
       "      <td>70.686313</td>\n",
       "      <td>5.963887</td>\n",
       "      <td>16.933547</td>\n",
       "      <td>41.470854</td>\n",
       "      <td>66.145767</td>\n",
       "      <td>111.525074</td>\n",
       "      <td>108.354216</td>\n",
       "      <td>35.258355</td>\n",
       "      <td>10.619401</td>\n",
       "      <td>...</td>\n",
       "      <td>33.993656</td>\n",
       "      <td>60.323832</td>\n",
       "      <td>54.807359</td>\n",
       "      <td>0.294852</td>\n",
       "      <td>20.970612</td>\n",
       "      <td>1</td>\n",
       "      <td>gua musang</td>\n",
       "      <td>my</td>\n",
       "      <td>asia</td>\n",
       "      <td>kualalumpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SpO₂         HR         PI         RR      EtCO₂       FiO₂  \\\n",
       "0  96.511604  70.263434  14.451123  17.461063  41.262037  78.519798   \n",
       "1  98.113516  72.872900   4.699563  17.231104  40.220086  64.283914   \n",
       "2  98.623248  81.418306  12.056504  16.832868  39.953184  77.164206   \n",
       "3  96.821905  70.263434  11.044410  14.876013  38.765113  59.296747   \n",
       "4  98.523262  70.686313   5.963887  16.933547  41.470854  66.145767   \n",
       "\n",
       "          PRV          BP  Skin Temperature  Motion/Activity index  ...  \\\n",
       "0  126.965235  109.471152         35.650826              11.429092  ...   \n",
       "1  139.509502  100.943658         35.313317              11.188645  ...   \n",
       "2  104.396821  107.401302         36.017931               8.980842  ...   \n",
       "3  147.612105  106.786082         35.433515               9.952747  ...   \n",
       "4  111.525074  108.354216         35.258355              10.619401  ...   \n",
       "\n",
       "   PPG waveform features  Signal Quality Index  Respiratory effort  \\\n",
       "0              36.604550             69.140438           57.097309   \n",
       "1              61.305805             50.733704           61.220158   \n",
       "2              49.432273             41.841466           57.554854   \n",
       "3              68.710875             47.524447           48.971775   \n",
       "4              33.993656             60.323832           54.807359   \n",
       "\n",
       "   O₂ extraction ratio        SNR  oximetry              station  code  \\\n",
       "0             0.210117  33.584512         1  paracho de verduzco    mx   \n",
       "1             0.293664  30.528645         1                 lutz    us   \n",
       "2             0.232518  22.357337         1      frankston south    au   \n",
       "3             0.288125  25.886190         0        port richmond    us   \n",
       "4             0.294852  20.970612         1           gua musang    my   \n",
       "\n",
       "   continent         city  \n",
       "0    america   mexicocity  \n",
       "1    america      newyork  \n",
       "2  australia    melbourne  \n",
       "3    america      newyork  \n",
       "4       asia  kualalumpur  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce984ca-4070-4a4c-be90-eab964966b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
